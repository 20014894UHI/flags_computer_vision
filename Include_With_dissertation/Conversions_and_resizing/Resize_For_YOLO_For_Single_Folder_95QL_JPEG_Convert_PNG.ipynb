{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716369aa-fc3b-487a-a3f2-a26b93e3e2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000007.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000008.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000009.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000006.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000011.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000012.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000014.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000020.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000023.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000030.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000005.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000010.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000000.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000001.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000002.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000003.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000013.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000016.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000017.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000018.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000019.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000022.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000026.jpg\n",
      "Resized and padded: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166_r\\Job_166000028.jpg\n",
      "Completed resizing and padding.\n",
      "Resizing and Padding completed at: 2025-01-13 09:03:06\n",
      "Adjusting annotations in folder: D:/FlagDetectionDatasets/ExportedDatasetsReducedML\\Job_166\n",
      "Completed annotation adjustment.\n",
      "Annotation Adjustment completed at: 2025-01-13 09:03:07\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def log_finish_time(task_name):\n",
    "    \"\"\"\n",
    "    Log the finish time of a task to the console.\n",
    "    \"\"\"\n",
    "    finish_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"{task_name} completed at: {finish_time}\")\n",
    "\n",
    "def resize_and_pad_single_folder(input_folder, output_folder, target_width, target_height):\n",
    "    \"\"\"\n",
    "    Resize landscape images to a target width and pad height to reach the target height.\n",
    "    Handles both .jpg and .png files.\n",
    "    Converts all images to JPEG format and saves them with 95 quality.\n",
    "    \"\"\"\n",
    "    print(f\"Processing folder: {input_folder}\")\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            output_file_name = os.path.splitext(file_name)[0] + \".jpg\"  # Convert all to JPEG\n",
    "            output_path = os.path.join(output_folder, output_file_name)\n",
    "\n",
    "            # Read the image\n",
    "            image = cv2.imread(input_path)\n",
    "            if image is None:\n",
    "                print(f\"Error reading {input_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            original_height, original_width = image.shape[:2]\n",
    "\n",
    "            # Resize the image to target width, keeping aspect ratio\n",
    "            scale_ratio = target_width / original_width\n",
    "            new_height = int(original_height * scale_ratio)\n",
    "            resized_image = cv2.resize(image, (target_width, new_height))\n",
    "\n",
    "            # Add padding to top and bottom to reach target height\n",
    "            padding_needed = target_height - new_height\n",
    "            if padding_needed > 0:\n",
    "                top_padding = padding_needed // 2\n",
    "                bottom_padding = padding_needed - top_padding\n",
    "                padded_image = cv2.copyMakeBorder(\n",
    "                    resized_image, top_padding, bottom_padding, 0, 0,\n",
    "                    borderType=cv2.BORDER_CONSTANT, value=[0, 0, 0]  # Black padding\n",
    "                )\n",
    "            else:\n",
    "                padded_image = resized_image\n",
    "\n",
    "            # Save the processed image as JPEG\n",
    "            cv2.imwrite(output_path, padded_image, [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
    "            print(f\"Resized and padded: {output_path}\")\n",
    "\n",
    "    print(\"Completed resizing and padding.\")\n",
    "    log_finish_time(\"Resizing and Padding\")\n",
    "\n",
    "def adjust_annotations_single_folder(image_folder, annotation_folder, output_annotation_folder, target_width, target_height):\n",
    "    \"\"\"\n",
    "    Adjust YOLO annotations for landscape images and save them for a batch test case.\n",
    "    \"\"\"\n",
    "    print(f\"Adjusting annotations in folder: {annotation_folder}\")\n",
    "\n",
    "    if not os.path.exists(output_annotation_folder):\n",
    "        os.makedirs(output_annotation_folder)\n",
    "\n",
    "    for annotation_file in os.listdir(annotation_folder):\n",
    "        if annotation_file.endswith('.txt'):\n",
    "            annotation_path = os.path.join(annotation_folder, annotation_file)\n",
    "            image_path = os.path.join(image_folder, annotation_file.replace('.txt', '.jpg'))\n",
    "            output_annotation_path = os.path.join(output_annotation_folder, annotation_file)\n",
    "\n",
    "            # Check if the corresponding image exists\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Image file not found for annotation: {annotation_file}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Get image dimensions\n",
    "            image = cv2.imread(image_path)\n",
    "            original_height, original_width = image.shape[:2]\n",
    "\n",
    "            padding_needed = target_height - int(original_height * (target_width / original_width))\n",
    "            top_padding = padding_needed // 2\n",
    "\n",
    "            adjusted_lines = []\n",
    "\n",
    "            # Read annotations\n",
    "            with open(annotation_path, 'r') as file:\n",
    "                annotations = file.readlines()\n",
    "\n",
    "            for line in annotations:\n",
    "                class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "\n",
    "                # Scale coordinates and dimensions\n",
    "                x_center_scaled = x_center * original_width\n",
    "                y_center_scaled = y_center * original_height\n",
    "                width_scaled = width * original_width\n",
    "                height_scaled = height * original_height\n",
    "\n",
    "                # Apply padding offsets\n",
    "                y_center_scaled += top_padding\n",
    "\n",
    "                # Normalize back to target dimensions\n",
    "                x_center_normalized = x_center_scaled / target_width\n",
    "                y_center_normalized = y_center_scaled / target_height\n",
    "                width_normalized = width_scaled / target_width\n",
    "                height_normalized = height_scaled / target_height\n",
    "\n",
    "                # Append adjusted annotation\n",
    "                adjusted_lines.append(\n",
    "                    f\"{int(class_id)} {x_center_normalized:.6f} {y_center_normalized:.6f} {width_normalized:.6f} {height_normalized:.6f}\"\n",
    "                )\n",
    "\n",
    "            # Save adjusted annotations\n",
    "            with open(output_annotation_path, 'w') as file:\n",
    "                file.write('\\n'.join(adjusted_lines))\n",
    "\n",
    "    print(\"Completed annotation adjustment.\")\n",
    "    log_finish_time(\"Annotation Adjustment\")\n",
    "\n",
    "# Paths and target dimensions\n",
    "parent_input_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsReducedML\"\n",
    "target_width = 1920\n",
    "target_height = 1080\n",
    "\n",
    "# only \"Job_166\"\n",
    "input_folder = os.path.join(parent_input_folder, \"Job_166\")\n",
    "output_folder = os.path.join(parent_input_folder, \"Job_166_r\")\n",
    "annotation_folder = input_folder  \n",
    "output_annotation_folder = output_folder  \n",
    "\n",
    "# Resize and pad images\n",
    "resize_and_pad_single_folder(input_folder, output_folder, target_width, target_height)\n",
    "\n",
    "# Adjust annotations\n",
    "adjust_annotations_single_folder(output_folder, annotation_folder, output_annotation_folder, target_width, target_height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da50626-2415-47a2-a3f5-c4e4c9e3f326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
