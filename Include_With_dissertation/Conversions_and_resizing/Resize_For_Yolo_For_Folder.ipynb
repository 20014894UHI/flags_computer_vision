{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0686a1f-ae5d-4e91-82ba-7ddb476ec518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting resizing and padding for landscape images...\n",
      "Completed resizing and padding for landscape images.\n",
      "Starting resizing ...\n",
      "Processing Job_155_000019.txt: top_padding=4\n",
      "Processing Job_155_000032.txt: top_padding=4\n",
      "Processing Job_155_000028.txt: top_padding=4\n",
      "Processing Job_155_000033.txt: top_padding=4\n",
      "Processing Job_155_000025.txt: top_padding=4\n",
      "Processing Job_155_000030.txt: top_padding=4\n",
      "Processing Job_155_000040.txt: top_padding=4\n",
      "Processing Job_155_000006.txt: top_padding=4\n",
      "Processing Job_155_000010.txt: top_padding=4\n",
      "Processing Job_155_000045.txt: top_padding=4\n",
      "Processing Job_155_000017.txt: top_padding=4\n",
      "Processing Job_155_000009.txt: top_padding=4\n",
      "Processing Job_155_000008.txt: top_padding=4\n",
      "Processing Job_155_000014.txt: top_padding=4\n",
      "Processing Job_155_000022.txt: top_padding=4\n",
      "Processing Job_155_000013.txt: top_padding=4\n",
      "Processing Job_155_000043.txt: top_padding=4\n",
      "Processing Job_155_000041.txt: top_padding=4\n",
      "Processing Job_155_000052.txt: top_padding=4\n",
      "Processing Job_155_000047.txt: top_padding=4\n",
      "Processing Job_155_000015.txt: top_padding=4\n",
      "Processing Job_155_000053.txt: top_padding=4\n",
      "Processing Job_155_000055.txt: top_padding=4\n",
      "Processing Job_155_000051.txt: top_padding=4\n",
      "Processing Job_155_000058.txt: top_padding=4\n",
      "Processing Job_155_000001.txt: top_padding=4\n",
      "Processing Job_155_000027.txt: top_padding=4\n",
      "Processing Job_155_000031.txt: top_padding=4\n",
      "Processing Job_155_000020.txt: top_padding=4\n",
      "Processing Job_155_000057.txt: top_padding=4\n",
      "Processing Job_155_000011.txt: top_padding=4\n",
      "Processing Job_155_000044.txt: top_padding=4\n",
      "Processing Job_155_000034.txt: top_padding=4\n",
      "Processing Job_155_000016.txt: top_padding=4\n",
      "Processing Job_155_000035.txt: top_padding=4\n",
      "Processing Job_155_000003.txt: top_padding=4\n",
      "Processing Job_155_000056.txt: top_padding=4\n",
      "Processing Job_155_000012.txt: top_padding=4\n",
      "Processing Job_155_000049.txt: top_padding=4\n",
      "Processing Job_155_000007.txt: top_padding=4\n",
      "Processing Job_155_000037.txt: top_padding=4\n",
      "Processing Job_155_000061.txt: top_padding=4\n",
      "Processing Job_155_000036.txt: top_padding=4\n",
      "Processing Job_155_000005.txt: top_padding=4\n",
      "Processing Job_155_000039.txt: top_padding=4\n",
      "Processing Job_155_000024.txt: top_padding=4\n",
      "Processing Job_155_000026.txt: top_padding=4\n",
      "Processing Job_155_000050.txt: top_padding=4\n",
      "Processing Job_155_000023.txt: top_padding=4\n",
      "Processing Job_155_000054.txt: top_padding=4\n",
      "Processing Job_155_000029.txt: top_padding=4\n",
      "Processing Job_155_000021.txt: top_padding=4\n",
      "Processing Job_155_000046.txt: top_padding=4\n",
      "Processing Job_155_000038.txt: top_padding=4\n",
      "Processing Job_155_000048.txt: top_padding=4\n",
      "Processing Job_155_000018.txt: top_padding=4\n",
      "Processing Job_155_000059.txt: top_padding=4\n",
      "Processing Job_155_000004.txt: top_padding=4\n",
      "Processing Job_155_000060.txt: top_padding=4\n",
      "Starting updating annotations ...\n"
     ]
    }
   ],
   "source": [
    "# Final resize before passing to Yolo \n",
    "# Images are landscape at this stage before being processed here \n",
    "# The goal is to convert all images to a height and width that is divisible by 32 and a target target_width = 1920\n",
    "# target_height = 1088 are passed which results in padding the top and bottom evenly by 4 pixels each only. \n",
    "# This is for individual folders and was set up as a test before moving to the one that handles folders of folders. \n",
    "# Copy any images already at target dimensions directly to the output folder, maintain original format \n",
    "# Copy annotations directly without adjustment.\n",
    "# Pad landscape iamges that have a smaller height \n",
    "# Save all resized or padded images in the same format as the original file \n",
    "# Only adjust annotations for images that need to be padded or resized. \n",
    "# Adjust annotations as needed, applying the padding offset for the y_center.\n",
    "\n",
    "# Final resize before passing to Yolo \n",
    "# Images are landscape at this stage before being processed here \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def resize_and_pad_even(input_folder, output_folder, target_width, target_height):\n",
    "    \"\"\"\n",
    "    Resize landscape images to a target width and pad height to reach the target height.\n",
    "    Handles both .jpg and .png files.\n",
    "    Ensures images are 1920 × 1080 before processing.\n",
    "    \"\"\"\n",
    "    print(\"Starting resizing and padding for landscape images...\")\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            file_extension = os.path.splitext(file_name)[1].lower()\n",
    "            output_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "            # Read the image\n",
    "            image = cv2.imread(input_path)\n",
    "            if image is None:\n",
    "                print(f\"Error reading {input_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            original_height, original_width = image.shape[:2]\n",
    "\n",
    "            # If the image is already at target dimensions, copy it\n",
    "            if original_width == target_width and original_height == target_height:\n",
    "                print(f\"Image {file_name} already at target dimensions. Copying to output folder.\")\n",
    "                cv2.imwrite(output_path, image)  # Copy the image directly in its original format\n",
    "                continue\n",
    "\n",
    "            # Resize the image to target width, keeping aspect ratio\n",
    "            scale_ratio = target_width / original_width\n",
    "            new_height = int(original_height * scale_ratio)\n",
    "            resized_image = cv2.resize(image, (target_width, new_height))\n",
    "\n",
    "            # Add padding to top and bottom to reach target height\n",
    "            padding_needed = target_height - new_height\n",
    "            if padding_needed > 0:\n",
    "                top_padding = padding_needed // 2\n",
    "                bottom_padding = padding_needed - top_padding\n",
    "                padded_image = cv2.copyMakeBorder(\n",
    "                    resized_image, top_padding, bottom_padding, 0, 0,\n",
    "                    borderType=cv2.BORDER_CONSTANT, value=[0, 0, 0]  # Black padding\n",
    "                )\n",
    "            else:\n",
    "                padded_image = resized_image\n",
    "\n",
    "            # Save the processed image in the original file format\n",
    "            cv2.imwrite(output_path, padded_image)\n",
    "\n",
    "    print(\"Completed resizing and padding for landscape images.\")\n",
    "\n",
    "\n",
    "def adjust_annotations_for_folder_landscape(input_annotation_folder, input_image_folder, output_annotation_folder, target_width, target_height):\n",
    "    \"\"\"\n",
    "    Adjust YOLO annotations for all landscape images in a folder and save them for a batch test case.\n",
    "    Handles both .jpg and .png files.\n",
    "    Ensures images are 1920 × 1080 before processing annotations.\n",
    "    \"\"\"\n",
    "    # Ensure output folder exists\n",
    "    if not os.path.exists(output_annotation_folder):\n",
    "        os.makedirs(output_annotation_folder)\n",
    "\n",
    "    # Process each annotation file\n",
    "    for annotation_file in os.listdir(input_annotation_folder):\n",
    "        if annotation_file.endswith('.txt'):\n",
    "            annotation_path = os.path.join(input_annotation_folder, annotation_file)\n",
    "            \n",
    "            # Look for both .jpg and .png images\n",
    "            image_path_jpg = os.path.join(input_image_folder, annotation_file.replace('.txt', '.jpg'))\n",
    "            image_path_png = os.path.join(input_image_folder, annotation_file.replace('.txt', '.png'))\n",
    "            image_path = image_path_jpg if os.path.exists(image_path_jpg) else image_path_png\n",
    "\n",
    "            output_annotation_path = os.path.join(output_annotation_folder, annotation_file)\n",
    "\n",
    "            # Check if the corresponding image exists\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Image file not found for annotation: {annotation_file}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Get image dimensions\n",
    "            image = cv2.imread(image_path)\n",
    "            original_height, original_width = image.shape[:2]\n",
    "\n",
    "            # If the image is already at target dimensions, copy annotation directly\n",
    "            if original_width == target_width and original_height == target_height:\n",
    "                print(f\"Annotation for {annotation_file} corresponds to an image already at target dimensions. Copying directly.\")\n",
    "                with open(annotation_path, 'r') as file:\n",
    "                    annotations = file.readlines()\n",
    "                with open(output_annotation_path, 'w') as file:\n",
    "                    file.writelines(annotations)\n",
    "                continue\n",
    "\n",
    "            # Calculate padding offset\n",
    "            padding_needed = target_height - original_height\n",
    "            top_padding = padding_needed // 2\n",
    "            print(f\"Processing {annotation_file}: top_padding={top_padding}\")\n",
    "\n",
    "            adjusted_lines = []\n",
    "\n",
    "            # Read annotations\n",
    "            with open(annotation_path, 'r') as file:\n",
    "                annotations = file.readlines()\n",
    "\n",
    "            for line in annotations:\n",
    "                class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "\n",
    "                # Scale coordinates and dimensions\n",
    "                x_center_scaled = x_center * original_width\n",
    "                y_center_scaled = y_center * original_height\n",
    "                width_scaled = width * original_width\n",
    "                height_scaled = height * original_height\n",
    "\n",
    "                # Reverse padding offset (move y_center back into padded space)\n",
    "                y_center_scaled += top_padding\n",
    "\n",
    "                # Clamp to image bounds\n",
    "                x_left = max(0, x_center_scaled - width_scaled / 2)\n",
    "                x_right = min(target_width, x_center_scaled + width_scaled / 2)\n",
    "                y_top = max(0, y_center_scaled - height_scaled / 2)\n",
    "                y_bottom = min(target_height, y_center_scaled + height_scaled / 2)\n",
    "\n",
    "                # Recalculate dimensions\n",
    "                width_clamped = max(0, x_right - x_left)\n",
    "                height_clamped = max(0, y_bottom - y_top)\n",
    "\n",
    "                if width_clamped > 0 and height_clamped > 0:\n",
    "                    x_center_normalized = (x_left + x_right) / (2 * target_width)\n",
    "                    y_center_normalized = (y_top + y_bottom) / (2 * target_height)\n",
    "                    width_normalized = width_clamped / target_width\n",
    "                    height_normalized = height_clamped / target_height\n",
    "\n",
    "                    # Append corrected annotation\n",
    "                    adjusted_lines.append(\n",
    "                        f\"{int(class_id)} {x_center_normalized:.6f} {y_center_normalized:.6f} {width_normalized:.6f} {height_normalized:.6f}\"\n",
    "                    )\n",
    "                else:\n",
    "                    print(f\"Bounding box for class {class_id} is invalid after clamping: skipping.\")\n",
    "\n",
    "            # Save adjusted annotations\n",
    "            with open(output_annotation_path, 'w') as file:\n",
    "                file.write('\\n'.join(adjusted_lines))\n",
    "\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "# Paths and target dimensions\n",
    "#input_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsSelected/Job_151\"\n",
    "#output_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsSelected/Job_151FINAL\"\n",
    "input_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsSelected/Job_155\"\n",
    "output_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsSelected/Job_155FINAL\"\n",
    "target_width = 1920\n",
    "target_height = 1088\n",
    "\n",
    "# Resize and PAD landscape images in the source folder - WILL PAD BY 4 PX AT TOP AND BOTTOM \n",
    "resize_and_pad_even(input_folder, output_folder, target_width, target_height)\n",
    "print(\"Starting resizing ...\")\n",
    "\n",
    "# Update annotations for all images in a a folader\n",
    "adjust_annotations_for_folder_landscape(input_folder, input_folder, output_folder, target_width, target_height)\n",
    "print(\"Starting updating annotations ...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd77f904-6688-47e5-a0be-02c755a177ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf313b5-7dc0-4ac4-95b9-ea01624c8db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
