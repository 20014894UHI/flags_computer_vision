{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c81792-f952-41a5-9077-d7433249ee40",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted from folderToSplice2: Job_121_000000_scaled_3_0.PNG and Job_121_000000_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000008.PNG and Job_121_000008.txt\n",
      "Deleted from folderToSplice2: Job_121_000016_scaled_3_0.PNG and Job_121_000016_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000024.PNG and Job_121_000024.txt\n",
      "Deleted from folderToSplice2: Job_121_000032_scaled_3_0.PNG and Job_121_000032_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000040.PNG and Job_121_000040.txt\n",
      "Deleted from folderToSplice2: Job_121_000048_scaled_3_0.PNG and Job_121_000048_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000056.PNG and Job_121_000056.txt\n",
      "Deleted from folderToSplice2: Job_121_000064_scaled_3_0.PNG and Job_121_000064_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000072.PNG and Job_121_000072.txt\n",
      "Deleted from folderToSplice2: Job_121_000080_scaled_3_0.PNG and Job_121_000080_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000088.PNG and Job_121_000088.txt\n",
      "Deleted from folderToSplice2: Job_121_000096_scaled_3_0.PNG and Job_121_000096_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000104.PNG and Job_121_000104.txt\n",
      "Deleted from folderToSplice2: Job_121_000112_scaled_3_0.PNG and Job_121_000112_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000120.PNG and Job_121_000120.txt\n",
      "Deleted from folderToSplice2: Job_121_000128_scaled_3_0.PNG and Job_121_000128_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000136.PNG and Job_121_000136.txt\n",
      "Deleted from folderToSplice2: Job_121_000144_scaled_3_0.PNG and Job_121_000144_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000152.PNG and Job_121_000152.txt\n",
      "Deleted from folderToSplice2: Job_121_000160_scaled_3_0.PNG and Job_121_000160_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000168.PNG and Job_121_000168.txt\n",
      "Deleted from folderToSplice2: Job_121_000176_scaled_3_0.PNG and Job_121_000176_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000184.PNG and Job_121_000184.txt\n",
      "Deleted from folderToSplice2: Job_121_000192_scaled_3_0.PNG and Job_121_000192_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000200.PNG and Job_121_000200.txt\n",
      "Deleted from folderToSplice2: Job_121_000208_scaled_3_0.PNG and Job_121_000208_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000216.PNG and Job_121_000216.txt\n",
      "Deleted from folderToSplice2: Job_121_000224_scaled_3_0.PNG and Job_121_000224_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000232.PNG and Job_121_000232.txt\n",
      "Deleted from folderToSplice2: Job_121_000240_scaled_3_0.PNG and Job_121_000240_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000248.PNG and Job_121_000248.txt\n",
      "Deleted from folderToSplice2: Job_121_000253_scaled_3_0.PNG and Job_121_000253_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000255.PNG and Job_121_000255.txt\n",
      "Deleted from folderToSplice2: Job_121_000257_scaled_3_0.PNG and Job_121_000257_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000265.PNG and Job_121_000265.txt\n",
      "Deleted from folderToSplice2: Job_121_000267_scaled_3_0.PNG and Job_121_000267_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000275.PNG and Job_121_000275.txt\n",
      "Deleted from folderToSplice2: Job_121_000283_scaled_3_0.PNG and Job_121_000283_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000291.PNG and Job_121_000291.txt\n",
      "Deleted from folderToSplice2: Job_121_000299_scaled_3_0.PNG and Job_121_000299_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000307.PNG and Job_121_000307.txt\n",
      "Deleted from folderToSplice2: Job_121_000313_scaled_3_0.PNG and Job_121_000313_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000321.PNG and Job_121_000321.txt\n",
      "Deleted from folderToSplice2: Job_121_000329_scaled_3_0.PNG and Job_121_000329_scaled_3_0.txt\n",
      "Deleted from folderToSplice1: Job_121_000337.PNG and Job_121_000337.txt\n",
      "Deleted from folderToSplice2: Job_121_000342_scaled_3_0.PNG and Job_121_000342_scaled_3_0.txt\n",
      "Splicing complete.\n"
     ]
    }
   ],
   "source": [
    "# Step 3 a_Step_x_ReduceDataset_by_pattern.jpynb\n",
    "# Dataset preparation - Delete patterns or sequences of files to reduce the dataset size - mitigate againt overfitting, reduce training time etc. \n",
    "\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def delete_by_pattern(whichfolder, patternInt, folder):\n",
    "    \"\"\"\n",
    "    Sorts files in the folder by name. Keeps the first image-annotation pair, deletes the next four pairs,\n",
    "    and writes a summary to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        whichfolder (str): The base directory containing the folders.\n",
    "        folder (str): The specific folder to process.\n",
    "        sub_folder_train (str): The sub-folder inside the folder to process.\n",
    "        csv_file (str): Path to the CSV file to write the summary.\n",
    "    \"\"\"\n",
    "    print(f\"Starting 1/{patternInt} pattern for {folder}\")\n",
    "    csv_file=\"dataset_reduced_by_pattern.csv\"\n",
    "    sub_folder_train = 'obj_train_data' \n",
    "\n",
    "    # Build the path to the target folder\n",
    "    path = os.path.join(whichfolder, folder)\n",
    "    path = os.path.join(path, sub_folder_train)\n",
    "\n",
    "    # Ensure the folder exists\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Error: The folder {path} does not exist.\")\n",
    "        return\n",
    "\n",
    "    # List all files in the folder\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    # Filter and sort files by type\n",
    "    image_files = sorted([f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    text_files = sorted([f for f in files if f.lower().endswith('.txt')])\n",
    "\n",
    "    # Ensure file pairs (images and corresponding annotations)\n",
    "    paired_files = []\n",
    "    for image_file in image_files:\n",
    "        base_name = os.path.splitext(image_file)[0]\n",
    "        annotation_file = f\"{base_name}.txt\"\n",
    "        if annotation_file in text_files:\n",
    "            paired_files.append((image_file, annotation_file))\n",
    "\n",
    "    # Record the initial count of image-annotation pairs\n",
    "    total_pairs_before = len(paired_files)\n",
    "    kept_count = 0\n",
    "    deleted_count = 0\n",
    "\n",
    "    # Keep one pair, delete the next n pairs\n",
    "    for i, (image_file, annotation_file) in enumerate(paired_files):\n",
    "        if i % patternInt == 0:\n",
    "            # Keep this pair\n",
    "            # print(f\"Keeping: {image_file} and {annotation_file}\")\n",
    "            kept_count += 1\n",
    "        else:\n",
    "            # Delete this pair\n",
    "            try:\n",
    "                os.remove(os.path.join(path, image_file))\n",
    "                os.remove(os.path.join(path, annotation_file))\n",
    "                # print(f\"Deleted: {image_file} and {annotation_file}\")\n",
    "                deleted_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting files {image_file} or {annotation_file}: {e}\")\n",
    "\n",
    "    # Calculate the number of pairs remaining\n",
    "    total_pairs_after = kept_count\n",
    "\n",
    "    # Write the summary to the CSV file\n",
    "    try:\n",
    "        with open(csv_file, mode='a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([folder, total_pairs_before, deleted_count, total_pairs_after])\n",
    "        print(f\"Summary written to {csv_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to CSV file: {e}\")\n",
    "\n",
    "    print(f\"Process complete. Kept {kept_count} images, deleted {deleted_count} image/annotation pairs from {folder}\")\n",
    "\n",
    "def delete_by_pattern_flat(whichfolder, patternInt, folder):\n",
    "    \"\"\"\n",
    "    Sorts files in the folder by name. Keeps the first image-annotation pair, deletes the next four pairs,\n",
    "    and writes a summary to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        whichfolder (str): The base directory containing the folders.\n",
    "        folder (str): The specific folder to process.\n",
    "        sub_folder_train (str): The sub-folder inside the folder to process.\n",
    "        csv_file (str): Path to the CSV file to write the summary.\n",
    "    \"\"\"\n",
    "    print(f\"Starting 1/{patternInt} pattern for {folder}\")\n",
    "    csv_file=\"dataset_reduced_by_pattern.csv\"\n",
    "    #sub_folder_train = 'obj_train_data' \n",
    "\n",
    "    # Build the path to the target folder\n",
    "    path = os.path.join(whichfolder, folder)\n",
    "    #path = os.path.join(path, sub_folder_train)\n",
    "\n",
    "    # Ensure the folder exists\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Error: The folder {path} does not exist.\")\n",
    "        return\n",
    "\n",
    "    # List all files in the folder\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    # Filter and sort files by type\n",
    "    image_files = sorted([f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    text_files = sorted([f for f in files if f.lower().endswith('.txt')])\n",
    "\n",
    "    # Ensure file pairs (images and corresponding annotations)\n",
    "    paired_files = []\n",
    "    for image_file in image_files:\n",
    "        base_name = os.path.splitext(image_file)[0]\n",
    "        annotation_file = f\"{base_name}.txt\"\n",
    "        if annotation_file in text_files:\n",
    "            paired_files.append((image_file, annotation_file))\n",
    "\n",
    "    # Record the initial count of image-annotation pairs\n",
    "    total_pairs_before = len(paired_files)\n",
    "    kept_count = 0\n",
    "    deleted_count = 0\n",
    "\n",
    "    # Keep one pair, delete the next n pairs\n",
    "    for i, (image_file, annotation_file) in enumerate(paired_files):\n",
    "        if i % patternInt == 0:\n",
    "            # Keep this pair\n",
    "            # print(f\"Keeping: {image_file} and {annotation_file}\")\n",
    "            kept_count += 1\n",
    "        else:\n",
    "            # Delete this pair\n",
    "            try:\n",
    "                os.remove(os.path.join(path, image_file))\n",
    "                os.remove(os.path.join(path, annotation_file))\n",
    "                # print(f\"Deleted: {image_file} and {annotation_file}\")\n",
    "                deleted_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting files {image_file} or {annotation_file}: {e}\")\n",
    "\n",
    "    # Calculate the number of pairs remaining\n",
    "    total_pairs_after = kept_count\n",
    "\n",
    "    # Write the summary to the CSV file\n",
    "    try:\n",
    "        with open(csv_file, mode='a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([folder, total_pairs_before, deleted_count, total_pairs_after])\n",
    "        print(f\"Summary written to {csv_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to CSV file: {e}\")\n",
    "\n",
    "    print(f\"Process complete. Kept {kept_count} images, deleted {deleted_count} image/annotation pairs from {folder}\")\n",
    "\n",
    "\n",
    "def delete_every_nth_flat(whichfolder, folder, deleteEveryInt):\n",
    "    \"\"\"\n",
    "    Deletes image and annotation pairs according to a pattern (e.g., every nth pair) after sorting them.\n",
    "\n",
    "    Args:\n",
    "        whichfolder (str): The base directory containing the folders.\n",
    "        folder (str): The specific folder to process.\n",
    "        deleteEveryInt (int): Delete every nth file pair.\n",
    "    \"\"\"\n",
    "    print(f\"Starting deletion of every {deleteEveryInt}th file pair in {folder}\")\n",
    "\n",
    "    # Build the path to the target folder\n",
    "    path = os.path.join(whichfolder, folder)\n",
    "\n",
    "    # Ensure the folder exists\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Error: The folder {path} does not exist.\")\n",
    "        return\n",
    "\n",
    "    # List and sort image and annotation files\n",
    "    files = sorted(os.listdir(path))\n",
    "    image_files = sorted([f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    annotation_files = sorted([f for f in files if f.lower().endswith('.txt')])\n",
    "\n",
    "    # Ensure only paired files are considered\n",
    "    paired_files = [\n",
    "        (img, f\"{os.path.splitext(img)[0]}.txt\")\n",
    "        for img in image_files\n",
    "        if f\"{os.path.splitext(img)[0]}.txt\" in annotation_files\n",
    "    ]\n",
    "\n",
    "    deleted_count = 0\n",
    "\n",
    "    for i, (image_file, annotation_file) in enumerate(paired_files):\n",
    "        if (i + 1) % deleteEveryInt == 0:\n",
    "            try:\n",
    "                os.remove(os.path.join(path, image_file))\n",
    "                os.remove(os.path.join(path, annotation_file))\n",
    "                print(f\"Deleted: {image_file} and {annotation_file}\")\n",
    "                deleted_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting pair {image_file} and {annotation_file}: {e}\")\n",
    "\n",
    "    print(f\"Process complete. Deleted {deleted_count} file pairs from {folder}.\")\n",
    "\n",
    "\n",
    "                          \n",
    "# Delete files by pattern in the selected set, e.g. delete every 2nd file in the set \n",
    "#base_path_tgt = 'D:/FlagDetectionDatasets/ExportedDatasetsReduced'\n",
    "base_path_tgt = 'D:/FlagDetectionDatasets/ExportedDatasetsSelected'\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_21', 3)\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_22', 3)\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_23', 3)\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_23_filter', 3)\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_28', 3)\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_29', 3)\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_30', 3)\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_31', 3)\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_32', 3)\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_36', 3)\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_41', 2)\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_43', 2)\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_51', 2)\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_51_Aug', 2)\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_52_Aug', 2)\n",
    "\n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_54', 3) # ran twice \n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_54', 3) \n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_60', 3) \n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_61', 3) \n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_71', 2) \n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_72', 2) \n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_78', 2) \n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_87', 2) \n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_88', 2) \n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_89', 2) \n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_104', 2) \n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_105', 2) \n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_106', 2) \n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_118', 2) \n",
    "#delete_every_nth_flat(base_path_tgt, 'Job_130', 2) \n",
    "\n",
    "\n",
    "##==========================================================================================#\n",
    "\n",
    "#delete_by_pattern(base_path_tgt, 3, 'Job_106') \n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_108') \n",
    "#delete_by_pattern(base_path_tgt, 4, 'Job_70') \n",
    "\n",
    "#delete_by_pattern(base_path_tgt, 2, 'Job_7') # frame step of 5 left 0, 5, 10, This will reduce to 0 10 , 20 \n",
    "#delete_by_pattern(base_path_tgt, 2, 'Job_11') # frame step of 5 left 1, 6, 11, This will reduce to 1, 11, 16, , 20 \n",
    "#delete_by_pattern(base_path_tgt, 4, 'Job_65') \n",
    "\n",
    "#delete_by_pattern(base_path_tgt, 3, 'Job_116')  # DID TWICE \n",
    "#delete_by_pattern(base_path_tgt, 3, 'Job_114') \n",
    "#Starting 1/3 pattern for Job_114\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 96 images, deleted 192 image/annotation pairs from Job_114\n",
    "\n",
    "#Starting 1/3 pattern for Job_116\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 176 images, deleted 352 image/annotation pairs from Job_116\n",
    "\n",
    "# Delete sequence - keep 1, delete 4 -  keep 1/5\n",
    "#delete_by_pattern(base_path_tgt,  folder=\"Job_15\", sub_folder_train = r'obj_train_data',5)\n",
    "#delete_by_pattern(base_path_tgt,  folder=\"Job_16\", sub_folder_train = r'obj_train_data',5)\n",
    "#delete_by_pattern(base_path_tgt,  folder=\"Job_17\", sub_folder_train = r'obj_train_data',5)\n",
    "#delete_by_pattern(base_path_tgt,  folder=\"Job_18\", sub_folder_train = r'obj_train_data',5)\n",
    "\n",
    "# Keep sequence is keep 1, delete 4, keep 1, delete 4... \n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_29')\n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_41')\n",
    "#delete_by_pattern(base_path_tgt, 4, 'Job_121_filter') \n",
    "#delete_by_pattern(base_path_tgt, 4, 'Job_121_a') # kept 2 deleted 8 \n",
    "\n",
    "\n",
    "#delete_by_pattern_flat(base_path_tgt, 2, 'Job_48') \n",
    "#delete_by_pattern_flat(base_path_tgt, 2, 'Job_128') \n",
    "\n",
    "#base_path_tgt = 'D:/FlagDetectionDatasets/Augmentation/scaled/augmented'\n",
    "#base_path_tgt = 'D:/FlagDetectionDatasets/Augmentation'\n",
    "#delete_by_pattern_flat(base_path_tgt, 10, 'Job_30') \n",
    "#base_path_tgt = 'D:/FlagDetectionDatasets/Augmentation'\n",
    "#delete_by_pattern_flat(base_path_tgt, 10, 'Switch_flag_into') \n",
    "\n",
    "#delete_by_pattern_flat(base_path_tgt, 5, 'Job_123') \n",
    "#base_path_tgt = 'D:/FlagDetectionDatasets/Augmentation/scaled/augmented'\n",
    "#delete_by_pattern_flat(base_path_tgt, 5, 'Job_120') \n",
    "#delete_by_pattern_flat(base_path_tgt, 5, 'Job_119') \n",
    "#delete_by_pattern_flat(base_path_tgt, 5, 'Job_118') \n",
    "\n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_115') \n",
    "#Starting 1/5 pattern for Job_115\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 63 images, deleted 249 image/annotation pairs from Job_115\n",
    "\n",
    "# delete_by_pattern(base_path_tgt, 5, 'Job_126') # RAN TWICE \n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_128')\n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_130')\n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_131')  # did this twice \n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_142') # did this twice \n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_143') ## REDO \n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_147')  # Did this twice so 1/10 \n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_160')  # WAS IN 5S ALREADY \n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_98')  # WAS IN 5S ALREADY \n",
    "#delete_by_pattern(base_path_tgt, 2, 'Job_98')  # then keep 1 in 2 so end result is 1 / 10 \n",
    "\n",
    "## Example Log from above\n",
    "\n",
    "#Starting 1/5 pattern for Job_143\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 27 images, deleted 105 image/annotation pairs from Job_143\n",
    "\n",
    "#Starting 1/5 pattern for Job_126\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 156 images, deleted 624 image/annotation pairs from Job_126\n",
    "#Starting 1/5 pattern for Job_128\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 107 images, deleted 425 image/annotation pairs from Job_128\n",
    "#Starting 1/5 pattern for Job_130\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 111 images, deleted 441 image/annotation pairs from Job_130\n",
    "#Starting 1/5 pattern for Job_131\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 108 images, deleted 432 image/annotation pairs from Job_131\n",
    "#Starting 1/5 pattern for Job_142\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 106 images, deleted 422 image/annotation pairs from Job_142\n",
    "#Starting 1/5 pattern for Job_160\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 59 images, deleted 234 image/annotation pairs from Job_160\n",
    "#Starting 1/5 pattern for Job_160\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 59 images, deleted 234 image/annotation pairs from Job_160\n",
    "\n",
    "# REDOO *********************************************\n",
    "# Starting 1/5 pattern for Job_143\n",
    "# Error: The folder D:/FlagDetectionDatasets/ExportedDatasetsReduced\\Job_143\\obj_train_data does not exist.\n",
    "\n",
    "# Starting 1/5 pattern for Job_147\n",
    "# Summary written to dataset_reduced_by_pattern.csv\n",
    "# Process complete. Kept 106 images, deleted 422 image/annotation pairs from Job_147\n",
    "\n",
    "\n",
    "# Keep 1, delete 9 pattern  - keep 1/10\n",
    "#delete_by_pattern(base_path_tgt, 10, 'Job_30') ## CHECK PATTERN CORRECT?\n",
    "#delete_by_pattern(base_path_tgt, 10, 'Job_31')\n",
    "#delete_by_pattern(base_path_tgt, 10, 'Job_32')\n",
    "\n",
    "#delete_by_pattern(base_path_tgt, 8, 'Job_72')  \n",
    "#delete_by_pattern(base_path_tgt, 10, 'Job_73')  \n",
    "\n",
    "#delete_by_pattern(base_path_tgt, 10, 'Job_73')\n",
    "#Starting 1/10 pattern for Job_73\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 88 images, deleted 788 image/annotation pairs from Job_73\n",
    "\n",
    "# Delete \n",
    "# delete_by_pattern(base_path_tgt,  2, 'Job_21')  # Keep all as frame step of 5 was effective \n",
    "\n",
    "# Keep 1/3 sequence \n",
    "#delete_by_pattern(base_path_tgt, 3, 'Job_118')\n",
    "\n",
    "#delete_by_pattern(base_path_tgt, 3, 'Job_117')  \n",
    "\n",
    "# Keep 1/4 sequence \n",
    "#delete_by_pattern(base_path_tgt, 4, 'Job_22')\n",
    "#delete_by_pattern(base_path_tgt, 10, 'Job_25')\n",
    "#delete_by_pattern_flat(base_path_tgt, 10, 'Job_27')  \n",
    "#delete_by_pattern_flat(base_path_tgt, 10, 'Job_30')  \n",
    "#delete_by_pattern_flat(base_path_tgt, 10, 'Job_31')  \n",
    "#delete_by_pattern_flat(base_path_tgt, 10, 'Job_43')  \n",
    "#delete_by_pattern_flat(base_path_tgt, 10, 'Job_51')  \n",
    "#delete_by_pattern_flat(base_path_tgt, 10, 'Job_60')  \n",
    "\n",
    "#delete_by_pattern(base_path_tgt, 4, 'Job_55')\n",
    "#delete_by_pattern(base_path_tgt, 4, 'Job_56')\n",
    "#delete_by_pattern(base_path_tgt, 4, 'Job_57')\n",
    "#delete_by_pattern(base_path_tgt, 4, 'Job_59')\n",
    "#delete_by_pattern(base_path_tgt, 4, 'Job_125')\n",
    "\n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_78') COULD DELETE 1/5 AGAIN \n",
    "#delete_by_pattern_flat(base_path_tgt, 10, 'Job_74')\n",
    "#delete_by_pattern_flat(base_path_tgt, 10, 'Job_75')\n",
    "#delete_by_pattern_flat(base_path_tgt, 10, 'Job_77')\n",
    "#delete_by_pattern(base_path_tgt, 10, 'Job_88')\n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_95')  # handheld\n",
    "#delete_by_pattern(base_path_tgt, 10, 'Job_36')  \n",
    "\n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_89')\n",
    "#delete_by_pattern(base_path_tgt, 5, 'Job_88')\n",
    "\n",
    "#delete_by_pattern_flat(base_path_tgt, 10, 'Job_98')  \n",
    "\n",
    "#delete_by_pattern_flat(base_path_tgt, 5, 'Job_109') \n",
    "#delete_by_pattern_flat(base_path_tgt, 5, 'Job_105')  \n",
    "\n",
    "# Example output: \n",
    "# Starting 1/4 pattern for Job_22\n",
    "# Summary written to dataset_reduced_by_pattern.csv\n",
    "# Process complete. Kept 569 images, deleted 1705 image/annotation pairs from Job_22\n",
    "#Starting 1/4 pattern for Job_125\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 96 images, deleted 288 image/annotation pairs from Job_125\n",
    "\n",
    "# Example for Job_15\n",
    "# Starting amt: 400. Deleted:  320 Remaining: 80\n",
    "#sub_folder_train = r'obj_train_data'\n",
    "\n",
    "## CHECK \n",
    "#Starting 1/10 pattern for Job_36\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 191 images, deleted 1710 image/annotation pairs from Job_36\n",
    "\n",
    "#Starting 1/5 pattern for Job_120\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 58 images, deleted 230 image/annotation pairs from Job_120\n",
    "\n",
    "#Starting 1/5 pattern for Job_120\n",
    "#Summary written to dataset_reduced_by_pattern.csv\n",
    "#Process complete. Kept 76 images, deleted 301 image/annotation pairs from Job_120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3d31f3-7858-4abb-a41d-2b2487cf1de8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
