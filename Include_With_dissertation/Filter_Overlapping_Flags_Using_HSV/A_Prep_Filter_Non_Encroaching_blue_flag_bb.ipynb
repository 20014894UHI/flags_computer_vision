{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7249381-c1f0-4088-ba30-e42118b5be12",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Job_37_Aug_Illum for flags where the blue flag bounding box does not overlap the red or red yellow flag in ...\n",
      "Base folder D:/FlagDetectionDatasets/Augmentation/Cleaning_Demos...\n",
      "Finished filtering Job_37_Aug_Illum, ...\n"
     ]
    }
   ],
   "source": [
    "# A_Prep_Filter_Non_Encroaching_blue_flag_bb.jpynb \n",
    "# Process images and associated annotation files in a job folder and filter out specific cases where a bounding box \n",
    "# of a given class (e.g., red or red-yellow flag) does not overlap with or contain a blue flag. \n",
    "# Find images where the red flag bounding box does not contain any portion of the blue flag\n",
    "# Searches through a folder of datasets; examine each image and its annotation in the obj_train_data sub-folder, \n",
    "# checks whether the class bounding box contains a strong contrast leading into a darker blue region.\n",
    "# If no such area is found, copy the image to a specified output folder.\n",
    "\n",
    "## Could improve by allowing an edge of e.g.3 pixels as in image 1918, 1920,  in series Job_23\n",
    "##  1921 ha tiny area 1945 etc. \n",
    "\n",
    "# 6. Check for Blue Flags\n",
    "# Calls the contains_blue_flag function to determine if the ROI contains a blue flag:\n",
    "# Converts the ROI to HSV color space.\n",
    "# Uses a mask to detect pixels in the blue color range.\n",
    "# Detects edges in the masked area using cv2.Canny.\n",
    "# If any edges are found, the script assumes a blue flag is present.\n",
    "# Helper Function: contains_blue_flag\n",
    "\n",
    "# Converts an image's ROI to HSV color space to separate colors by hue.\n",
    "# Masks areas within a specific blue color range (using lower and upper thresholds).\n",
    "# Uses cv2.Canny to detect edges in the blue mask.\n",
    "# Purpose: To ensure that only images where bounding boxes of class class_id (e.g., red or red-yellow flags) do not encroach on blue flags are retained for further processing.\n",
    "# Output: A filtered dataset of images and annotations in the _a folder.\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "def filter_non_encroaching_blue_flag_bb(base_folder, job, class_id):\n",
    "    \"\"\"\n",
    "    In job folders, find images where class 0  or 1 bounding box does not contain/overlap with a blue flag.\n",
    "    :param base_folder: Path to the folder containing job folders.\n",
    "    :param class_id: Class ID for which bounding box is checked.\n",
    "    \"\"\"\n",
    "    print(f\"Checking {job} for flags where the blue flag bounding box does not overlap the red or red yellow flag in ...\")\n",
    "    print(f\"Base folder {base_folder}...\")\n",
    "\n",
    "    #for job_folder in os.listdir(base_folder):\n",
    "    suffix = \"_filter\"\n",
    "    new_folder = job + suffix\n",
    "        \n",
    "    job_path = os.path.join(base_folder, job)\n",
    "    output_folder= os.path.join(base_folder, new_folder) # ... reduced/job_n_a\n",
    "    obj_train_new_data_path = os.path.join(output_folder, \"obj_train_data\") #reduced/job_n_a/obj_train_data\n",
    "    obj_train_data_path = os.path.join(job_path, \"obj_train_data\")\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    #print(f\"Checking {job} for non overlapping flags...\")\n",
    "\n",
    "    if not os.path.exists(obj_train_new_data_path):\n",
    "        os.makedirs(obj_train_new_data_path)\n",
    "         \n",
    "    if not os.path.exists(obj_train_data_path):\n",
    "        print(f\"No obj_train_data folder in {job}, skipping...\")\n",
    "        return\n",
    "        \n",
    "    for file in os.listdir(obj_train_data_path):\n",
    "        if file.lower().endswith(\".txt\"):  # Annotation file\n",
    "            annotation_path = os.path.join(obj_train_data_path, file)\n",
    "            image_path = os.path.join(obj_train_data_path, file.rsplit('.', 1)[0] + \".PNG\")\n",
    "            #images = [f for f in os.listdir(obj_train_data_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Image file {image_path} not found, skipping...\")\n",
    "                continue\n",
    "                \n",
    "            # Read annotation\n",
    "            with open(annotation_path, 'r') as f:\n",
    "                annotations = f.readlines()\n",
    "                \n",
    "            # Check for class 0 bounding boxes\n",
    "            for line in annotations:\n",
    "                elements = line.strip().split()\n",
    "                if int(elements[0]) == class_id:\n",
    "                    # Extract bounding box details\n",
    "                    x_center, y_center, width, height = map(float, elements[1:])          \n",
    "                    # Convert normalized coordinates to pixel values\n",
    "                    image = cv2.imread(image_path)\n",
    "                    img_height, img_width = image.shape[:2]\n",
    "                    x1 = int((x_center - width / 2) * img_width)\n",
    "                    y1 = int((y_center - height / 2) * img_height)\n",
    "                    x2 = int((x_center + width / 2) * img_width)\n",
    "                    y2 = int((y_center + height / 2) * img_height)\n",
    "                        \n",
    "                    # Extract the region of interest (ROI)\n",
    "                    roi = image[y1:y2, x1:x2]\n",
    "\n",
    "                    #if contains_blue_flag(roi):\n",
    "                        # print(f\"Contains blue flag? {image_path} \")\n",
    "                        \n",
    "                    # Check for strong contrast into darker blue\n",
    "                    if not contains_blue_flag(roi):\n",
    "                      #  if not os.path.exists(output_folder):\n",
    "                      #  os.makedirs(output_folder)\n",
    "                        #print(f\"Beginning filtering {job} for non overlapping flags...\")\n",
    "    \n",
    "                        # Move image and annotation to output folder\n",
    "                        # shutil.copy(image_path, os.path.join(output_folder, os.path.basename(image_path)))\n",
    "                        shutil.move(image_path, os.path.join(obj_train_new_data_path, os.path.basename(image_path)))\n",
    "                        shutil.move(annotation_path, os.path.join(obj_train_new_data_path, os.path.basename(annotation_path)))\n",
    "                        #shutil.move(image_path, os.path.join(obj_train_new_data_path, os.path.basename(image_path)))\n",
    "                        #shutil.move(annotation_path, os.path.join(obj_train_new_data_path, os.path.basename(annotation_path)))\n",
    "                        # print(f\"Moved {os.path.basename(image_path)} to {output_folder}\")\n",
    "                        break\n",
    "    print(f\"Finished filtering {job}, ...\")\n",
    "\n",
    "def filter_non_encroaching_blue_flag_bb_flat(base_folder, job, class_id):\n",
    "    \"\"\"\n",
    "    In job folders, find images where class 0  or 1 bounding box does not contain/overlap with a blue flag.\n",
    "    :param base_folder: Path to the folder containing job folders.\n",
    "    :param class_id: Class ID for which bounding box is checked.\n",
    "    \"\"\"\n",
    "    print(f\"Checking {job} for flags where the blue flag bounding box does not overlap the red or red yellow flag in ...\")\n",
    "    print(f\"Base folder {base_folder}...\")\n",
    "\n",
    "    #for job_folder in os.listdir(base_folder):\n",
    "    suffix = \"_filter\"\n",
    "    new_folder = job + suffix\n",
    "        \n",
    "    job_path = os.path.join(base_folder, job)\n",
    "    output_folder= os.path.join(base_folder, new_folder) # ... reduced/job_n_a\n",
    "    obj_train_new_data_path = output_folder #os.path.join(output_folder, \"obj_train_data\") #reduced/job_n_a/obj_train_data\n",
    "    obj_train_data_path = job_path #os.path.join(job_path, \"obj_train_data\")\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    #print(f\"Checking {job} for non overlapping flags...\")\n",
    "\n",
    "    if not os.path.exists(obj_train_new_data_path):\n",
    "        os.makedirs(obj_train_new_data_path)\n",
    "         \n",
    "    if not os.path.exists(obj_train_data_path):\n",
    "        print(f\"No obj_train_data folder in {job}, skipping...\")\n",
    "        return\n",
    "        \n",
    "    for file in os.listdir(obj_train_data_path):\n",
    "        if file.lower().endswith(\".txt\"):  # Annotation file\n",
    "            annotation_path = os.path.join(obj_train_data_path, file)\n",
    "            image_path = os.path.join(obj_train_data_path, file.rsplit('.', 1)[0] + \".PNG\")\n",
    "            #images = [f for f in os.listdir(obj_train_data_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Image file {image_path} not found, skipping...\")\n",
    "                continue\n",
    "                \n",
    "            # Read annotation\n",
    "            with open(annotation_path, 'r') as f:\n",
    "                annotations = f.readlines()\n",
    "                \n",
    "            # Check for class 0 bounding boxes\n",
    "            for line in annotations:\n",
    "                elements = line.strip().split()\n",
    "                if int(elements[0]) == class_id:\n",
    "                    # Extract bounding box details\n",
    "                    x_center, y_center, width, height = map(float, elements[1:])          \n",
    "                    # Convert normalized coordinates to pixel values\n",
    "                    image = cv2.imread(image_path)\n",
    "                    img_height, img_width = image.shape[:2]\n",
    "                    x1 = int((x_center - width / 2) * img_width)\n",
    "                    y1 = int((y_center - height / 2) * img_height)\n",
    "                    x2 = int((x_center + width / 2) * img_width)\n",
    "                    y2 = int((y_center + height / 2) * img_height)\n",
    "                        \n",
    "                    # Extract the region of interest (ROI)\n",
    "                    roi = image[y1:y2, x1:x2]\n",
    "\n",
    "                    #if contains_blue_flag(roi):\n",
    "                        # print(f\"Contains blue flag? {image_path} \")\n",
    "                        \n",
    "                    # Check for strong contrast into darker blue\n",
    "                    if not contains_blue_flag(roi):\n",
    "                      #  if not os.path.exists(output_folder):\n",
    "                      #  os.makedirs(output_folder)\n",
    "                        #print(f\"Beginning filtering {job} for non overlapping flags...\")\n",
    "    \n",
    "                        # Move image and annotation to output folder\n",
    "                        # shutil.copy(image_path, os.path.join(output_folder, os.path.basename(image_path)))\n",
    "                        shutil.move(image_path, os.path.join(obj_train_new_data_path, os.path.basename(image_path)))\n",
    "                        shutil.move(annotation_path, os.path.join(obj_train_new_data_path, os.path.basename(annotation_path)))\n",
    "                        #shutil.move(image_path, os.path.join(obj_train_new_data_path, os.path.basename(image_path)))\n",
    "                        #shutil.move(annotation_path, os.path.join(obj_train_new_data_path, os.path.basename(annotation_path)))\n",
    "                        # print(f\"Moved {os.path.basename(image_path)} to {output_folder}\")\n",
    "                        break\n",
    "    print(f\"Finished filtering {job}, ...\")\n",
    "\n",
    "def contains_blue_flag(roi):\n",
    "    \"\"\"\n",
    "    Check if a region of interest contains a blue flag.\n",
    "    :param roi: Region of interest (ROI) as a numpy array.\n",
    "    :return: True if blue flag is detected, False otherwise.\n",
    "    \"\"\"\n",
    "    # Convert ROI to HSV color space\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    # Define HSV range for darker blue\n",
    "    #lower_blue = np.array([100, 150, 50])  \n",
    "    #lower_blue = np.array([204, 20, 86])    \n",
    "    # Photoshop, OpenCV use different terminologieS - HSB in PS underlying maths/scaling for HSB and HSV is same.\n",
    "    upper_blue = np.array([130, 255, 200])\n",
    "    lower_blue = np.array([90, 50, 50])  # Broaden range for darker/lighter blue\n",
    "    upper_blue = np.array([140, 255, 255])\n",
    "    # cde1f1 - try 207 15 94 = hsb? for job 121 image 000000.png 204 20 86 ?\n",
    "    # Create a mask for blue regions\n",
    "    blue_mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    ## hex code for imageiin 121 is cde1f1\n",
    "    # Detect edges within the blue mask\n",
    "    edges = cv2.Canny(blue_mask, 100, 200)\n",
    "    # Check if there are strong edges in the blue mask\n",
    "    if np.any(edges):\n",
    "        return True  # Blue flag detected\n",
    "    return False  # No blue flag detected\n",
    "    #print(f\"No blue flag detected\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_folder = r'D:\\FlagDetectionDatasets\\ExportedDatasetsReduced'\n",
    "    base_folder = 'D:/FlagDetectionDatasets/Augmentation/Cleaning_Demos' #Job_24'\n",
    "    filter_non_encroaching_blue_flag_bb_flat(base_folder, 'Job_37_Aug_Illum', 1)   ## 1 is for the red_yellow flag \n",
    "    # filter_non_encroaching_blue_flag_bb(base_folder, 'Job_121', 1)   ## 1 is for the red_yellow flag \n",
    "    #filter_non_encroaching_blue_flag_bb(base_folder, 'Job_23', 0)   # Red flag \n",
    "    #filter_non_encroaching_blue_flag_bb_flat(base_folder, 'Job_24', 0)   # Red flag \n",
    "    #filter_non_encroaching_blue_flag_bb(base_folder, 'Job_23', 0) # red flag \n",
    "    #filter_non_encroaching_blue_flag_bb(base_folder, 'Job_23',0)\n",
    "    #filter_non_encroaching_blue_flag_bb(base_folder, 'Job_24',0)\n",
    "    #filter_non_encroaching_blue_flag_bb_flat(base_folder, 'Job_25',0) # 0 = Red flag  \n",
    "    # filter_non_encroaching_blue_flag_bb(base_folder, 'Job_27', 0)\n",
    "    #filter_non_encroaching_blue_flag_bb_flat(base_folder, 'Job_28', 0)\n",
    "    #filter_non_encroaching_blue_flag_bb_flat(base_folder, 'Job_24', 0)\n",
    "\n",
    "    #filter_non_encroaching_blue_flag_bb(base_folder, 'Job_28', 0)  # red flag \n",
    "    # filter_non_encroaching_blue_flag_bb(base_folder, 'Job_96', 0)  ## red flag \n",
    "    #filter_non_encroaching_blue_flag_bb(base_folder, 'Job_37', 0)  ## CHECK RESULT FOR jOB 37\n",
    "    # filter_non_encroaching_blue_flag_bb(base_folder, 'Job_119', 1)   ## 1 red_yellow flag # \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0474ee-ca3e-4729-aa38-8d038db9355f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
