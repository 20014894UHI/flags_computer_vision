{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "495e3051-cde9-4022-ad4d-2d166662b97d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Job_97:  threshold: nan\n",
      "Skipping Job_97 as images already exist in the target folder.\n",
      "Processing Job_96:  threshold: 0.9\n",
      "Job 'Job_96':\n",
      " - Before processing : 300\n",
      " - Filtered after processing: 1\n",
      " - Retained %:0.33\n",
      "Processing Job_95:  threshold: nan\n",
      "Skipping Job_95 as images already exist in the target folder.\n",
      "Processing Job_88:  threshold: 0.97\n",
      "Job 'Job_88':\n",
      " - Before processing : 708\n",
      " - Filtered after processing: 339\n",
      " - Retained %:47.88\n",
      "Processing Job_76:  threshold: 0.97\n",
      "Job 'Job_76':\n",
      " - Before processing : 540\n",
      " - Filtered after processing: 535\n",
      " - Retained %:99.07\n",
      "Processing Job_73:  threshold: 0.97\n",
      "Job 'Job_73':\n",
      " - Before processing : 601\n",
      " - Filtered after processing: 601\n",
      " - Retained %:100.00\n",
      "Processing Job_70:  threshold: nan\n",
      "Skipping Job_70 as images already exist in the target folder.\n",
      "Processing Job_69:  threshold: 0.96\n",
      "Job 'Job_69':\n",
      " - Before processing : 297\n",
      " - Filtered after processing: 158\n",
      " - Retained %:53.20\n",
      "Processing Job_65:  threshold: 0.965\n",
      "Job 'Job_65':\n",
      " - Before processing : 588\n",
      " - Filtered after processing: 361\n",
      " - Retained %:61.39\n",
      "Processing Job_50:  threshold: nan\n",
      "Skipping Job_50 as images already exist in the target folder.\n",
      "Processing Job_48:  threshold: 0.97\n",
      "Job 'Job_48':\n",
      " - Before processing : 1584\n",
      " - Filtered after processing: 1218\n",
      " - Retained %:76.89\n",
      "Processing Job_42:  threshold: 0.965\n",
      "Job 'Job_42':\n",
      " - Before processing : 1536\n",
      " - Filtered after processing: 1076\n",
      " - Retained %:70.05\n",
      "Processing Job_29:  threshold: 0.965\n",
      "Job 'Job_29':\n",
      " - Before processing : 1301\n",
      " - Filtered after processing: 592\n",
      " - Retained %:45.50\n",
      "Processing Job_28:  threshold: nan\n",
      "Skipping Job_28 as images already exist in the target folder.\n",
      "Processing Job_27:  threshold: 0.94\n",
      "Job 'Job_27':\n",
      " - Before processing : 4264\n",
      " - Filtered after processing: 1906\n",
      " - Retained %:44.70\n",
      "Processing Job_25:  threshold: 0.94\n",
      "Job 'Job_25':\n",
      " - Before processing : 2500\n",
      " - Filtered after processing: 1166\n",
      " - Retained %:46.64\n",
      "Processing Job_24:  threshold: nan\n",
      "Skipping Job_24 as images already exist in the target folder.\n",
      "Processing Job_23:  threshold: nan\n",
      "Skipping Job_23 as images already exist in the target folder.\n",
      "Processing Job_21:  threshold: nan\n",
      "Skipping Job_21 as images already exist in the target folder.\n",
      "Processing Job_126:  threshold: nan\n",
      "Skipping Job_126 as images already exist in the target folder.\n",
      "Processing Job_123:  threshold: 0.94\n",
      "Job 'Job_123':\n",
      " - Before processing : 300\n",
      " - Filtered after processing: 172\n",
      " - Retained %:57.33\n",
      "Processing Job_121:  threshold: nan\n",
      "Skipping Job_121 as images already exist in the target folder.\n",
      "Processing Job_119:  threshold: 0.965\n",
      "Job 'Job_119':\n",
      " - Before processing : 444\n",
      " - Filtered after processing: 195\n",
      " - Retained %:43.92\n",
      "Processing Job_118:  threshold: 0.955\n",
      "Job 'Job_118':\n",
      " - Before processing : 312\n",
      " - Filtered after processing: 138\n",
      " - Retained %:44.23\n",
      "Processing Job_115:  threshold: 0.955\n",
      "Job 'Job_115':\n",
      " - Before processing : 312\n",
      " - Filtered after processing: 138\n",
      " - Retained %:44.23\n",
      "Processing Job_114:  threshold: nan\n",
      "Skipping Job_114 as images already exist in the target folder.\n",
      "Processing Job_108:  threshold: nan\n",
      "Skipping Job_108 as images already exist in the target folder.\n",
      "Processing Job_106:  threshold: nan\n",
      "Skipping Job_106 as images already exist in the target folder.\n",
      "Processing Job_104:  threshold: nan\n",
      "Skipping Job_104 as images already exist in the target folder.\n",
      "Processing Job_89:  threshold: nan\n",
      "Skipping Job_89 as images already exist in the target folder.\n",
      "Processing Job_72:  threshold: nan\n",
      "Skipping Job_72 as images already exist in the target folder.\n",
      "Processing Job_67:  threshold: nan\n",
      "Skipping Job_67 as images already exist in the target folder.\n",
      "Processing Job_55:  threshold: nan\n",
      "Skipping Job_55 as images already exist in the target folder.\n",
      "Processing Job_54:  threshold: nan\n",
      "Skipping Job_54 as images already exist in the target folder.\n",
      "Processing Job_37:  threshold: nan\n",
      "Skipping Job_37 as images already exist in the target folder.\n",
      "Processing Job_131:  threshold: nan\n",
      "Skipping Job_131 as images already exist in the target folder.\n",
      "Processing Job_130:  threshold: nan\n",
      "Skipping Job_130 as images already exist in the target folder.\n",
      "Processing Job_13:  threshold: 0.98\n",
      "Job 'Job_13':\n",
      " - Before processing : 401\n",
      " - Filtered after processing: 157\n",
      " - Retained %:39.15\n",
      "Processing Job_128:  threshold: 0.98\n",
      "Job 'Job_128':\n",
      " - Before processing : 532\n",
      " - Filtered after processing: 168\n",
      " - Retained %:31.58\n",
      "Processing Job_125:  threshold: 0.98\n",
      "Job 'Job_125':\n",
      " - Before processing : 384\n",
      " - Filtered after processing: 153\n",
      " - Retained %:39.84\n",
      "Processing Job_117:  threshold: 0.98\n",
      "Job 'Job_117':\n",
      " - Before processing : 444\n",
      " - Filtered after processing: 105\n",
      " - Retained %:23.65\n",
      "Processing Job_87:  threshold: 0.98\n",
      "Job 'Job_87':\n",
      " - Before processing : 1128\n",
      " - Filtered after processing: 269\n",
      " - Retained %:23.85\n",
      "Processing Job_8:  threshold: 0.9775\n",
      "Job 'Job_8':\n",
      " - Before processing : 802\n",
      " - Filtered after processing: 559\n",
      " - Retained %:69.70\n",
      "Processing Job_7:  threshold: 0.9775\n",
      "Job 'Job_7':\n",
      " - Before processing : 725\n",
      " - Filtered after processing: 483\n",
      " - Retained %:66.62\n",
      "Processing Job_61:  threshold: 0.985\n",
      "Job 'Job_61':\n",
      " - Before processing : 551\n",
      " - Filtered after processing: 253\n",
      " - Retained %:45.92\n",
      "Processing Job_60:  threshold: 0.99\n",
      "Job 'Job_60':\n",
      " - Before processing : 1620\n",
      " - Filtered after processing: 1076\n",
      " - Retained %:66.42\n",
      "Processing Job_59:  threshold: 0.99\n",
      "Job 'Job_59':\n",
      " - Before processing : 201\n",
      " - Filtered after processing: 91\n",
      " - Retained %:45.27\n",
      "Processing Job_57:  threshold: 0.99\n",
      "Job 'Job_57':\n",
      " - Before processing : 528\n",
      " - Filtered after processing: 157\n",
      " - Retained %:29.73\n",
      "Processing Job_18:  threshold: 0.99\n",
      "Job 'Job_18':\n",
      " - Before processing : 400\n",
      " - Filtered after processing: 256\n",
      " - Retained %:64.00\n",
      "Processing Job_17:  threshold: 0.99\n",
      "Job 'Job_17':\n",
      " - Before processing : 400\n",
      " - Filtered after processing: 258\n",
      " - Retained %:64.50\n",
      "Processing Job_16:  threshold: 0.99\n",
      "Job 'Job_16':\n",
      " - Before processing : 400\n",
      " - Filtered after processing: 190\n",
      " - Retained %:47.50\n",
      "Processing Job_15:  threshold: 0.99\n",
      "Job 'Job_15':\n",
      " - Before processing : 400\n",
      " - Filtered after processing: 215\n",
      " - Retained %:53.75\n",
      "Processing Job_12:  threshold: 0.99\n",
      "Job 'Job_12':\n",
      " - Before processing : 900\n",
      " - Filtered after processing: 725\n",
      " - Retained %:80.56\n",
      "Processing Job_11:  threshold: 0.99\n",
      "Job 'Job_11':\n",
      " - Before processing : 700\n",
      " - Filtered after processing: 487\n",
      " - Retained %:69.57\n",
      "Processing Job_152:  threshold: nan\n",
      "Skipping Job_152 as images already exist in the target folder.\n",
      "Processing Job_56:  threshold: 0.975\n",
      "Job 'Job_56':\n",
      " - Before processing : 276\n",
      " - Filtered after processing: 99\n",
      " - Retained %:35.87\n",
      "Processing Job_105:  threshold: 0.975\n",
      "Job 'Job_105':\n",
      " - Before processing : 804\n",
      " - Filtered after processing: 342\n",
      " - Retained %:42.54\n",
      "Processing Job_116:  threshold: nan\n",
      "Skipping Job_116 as images already exist in the target folder.\n",
      "Processing Job_142:  threshold: 0.98\n",
      "Job 'Job_142':\n",
      " - Before processing : 528\n",
      " - Filtered after processing: 85\n",
      " - Retained %:16.10\n",
      "Processing Job_143:  threshold: nan\n",
      "Skipping Job_143 as images already exist in the target folder.\n",
      "Processing Job_145:  threshold: nan\n",
      "Skipping Job_145 as images already exist in the target folder.\n",
      "Processing Job_146:  threshold: nan\n",
      "Skipping Job_146 as images already exist in the target folder.\n",
      "Processing Job_147:  threshold: 0.975\n",
      "Job 'Job_147':\n",
      " - Before processing : 528\n",
      " - Filtered after processing: 246\n",
      " - Retained %:46.59\n",
      "Processing Job_151:  threshold: nan\n",
      "Skipping Job_151 as images already exist in the target folder.\n"
     ]
    }
   ],
   "source": [
    "## Conpare and filter Frames Round 2 v2 \n",
    "## Explanation of Updates\n",
    "## Adding copied_counts: Each job's copied image count is stored in a dictionary list called copied_counts.\n",
    "## Writing to CSV: After processing all jobs, copied_counts is converted to a DataFrame and merged with the original CSV on the Job column, then saved back to the CSV file with the new column.\n",
    "## This will update the CSV with the new copied image counts for each job after processing.\n",
    "## sTARTONGAT 23:41 NOV 1ST \n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# COPY JOBS THAT SHOULDN'TBE FILTERED BUT ARE STILL FOR TESTING AND UPDATE CODE \n",
    "\n",
    "# Function to load thresholds from CSV\n",
    "def load_thresholds_from_csv(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    return {row['Job']: row['New threshold'] for _, row in df.iterrows() if str(row['Job']).startswith('Job_')}, df\n",
    "\n",
    "# Function to check if images are similar\n",
    "def is_similar(image1, image2, threshold):\n",
    "    #print(f\"Processing {job}:  threshold: {threshold}\")\n",
    "\n",
    "    if image1.shape != image2.shape:\n",
    "        return False\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    score, _ = ssim(gray1, gray2, full=True)\n",
    "    return score > threshold\n",
    "\n",
    "# Function to extract numeric part from filenames for sorting\n",
    "def extract_numeric_part(filename):\n",
    "    return int(''.join(filter(str.isdigit, filename)))\n",
    "\n",
    "# Function to process jobs\n",
    "def process_jobs(parent_folder, thresholds, dest_folder, csv_file):\n",
    "    _, csv_df = load_thresholds_from_csv(csv_file)\n",
    "    copied_counts = []\n",
    "\n",
    "    for job, threshold in thresholds.items():\n",
    "        # The threshold is in the format e.g.95 for 95%\n",
    "        # NB REMOVE THIS Need to divide by 100 \n",
    "        ## threshold = threshold/100\n",
    "        job_folder = os.path.join(parent_folder, job, 'obj_train_data')\n",
    "        output_folder = os.path.join(dest_folder, job, 'obj_train_data')\n",
    "\n",
    "        print(f\"Processing {job}:  threshold: {threshold}\")\n",
    "\n",
    "        # Skip job if target folder already contains images\n",
    "        if os.path.exists(output_folder) and len(os.listdir(output_folder)) > 0:\n",
    "            print(f\"Skipping {job} as images already exist in the target folder.\")\n",
    "            continue\n",
    "\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Get sorted list of image files in obj_train_data\n",
    "        image_files = sorted(\n",
    "            [f for f in os.listdir(job_folder) if f.lower().endswith(('.jpg', '.png'))],\n",
    "            key=extract_numeric_part\n",
    "        )\n",
    "\n",
    "        prev_image = None\n",
    "        copied_images_count = 0\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(job_folder, image_file)\n",
    "            text_path = os.path.splitext(image_path)[0] + '.txt'\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # Copy the first image and text file\n",
    "            if prev_image is None:\n",
    "                prev_image = image\n",
    "           \n",
    "                shutil.copy(image_path, os.path.join(output_folder, image_file))\n",
    "                if os.path.exists(text_path):\n",
    "                    shutil.copy(text_path, os.path.join(output_folder, os.path.basename(text_path)))\n",
    "                copied_images_count += 1\n",
    "                continue\n",
    "\n",
    "            # Handle copy without comparison if threshold is NaN\n",
    "            if pd.isna(threshold):\n",
    "                shutil.copy(image_path, os.path.join(output_folder, image_file))\n",
    "                if os.path.exists(text_path):\n",
    "                    shutil.copy(text_path, os.path.join(output_folder, os.path.basename(text_path)))\n",
    "                copied_images_count += 1\n",
    "            else:\n",
    "                # print(f\" - Checkingimage silimarity using threshold: {threshold}\")\n",
    "                if not is_similar(prev_image, image, threshold):\n",
    "                    prev_image = image\n",
    "                    shutil.copy(image_path, os.path.join(output_folder, image_file))\n",
    "                    if os.path.exists(text_path):\n",
    "                        shutil.copy(text_path, os.path.join(output_folder, os.path.basename(text_path)))\n",
    "                    copied_images_count += 1\n",
    "\n",
    "        # Log the job and image counts\n",
    "        total_images_count = len(image_files)\n",
    "        #print(f\"Processed {job}: {total_images_count} images before processing, {copied_images_count} images copied, threshold: {threshold}\")\n",
    "\n",
    "        # Print summary for the current child folder\n",
    "        print(f\"Job '{job}':\")\n",
    "        print(f\" - Before processing : {total_images_count}\")\n",
    "        print(f\" - Filtered after processing: {copied_images_count}\")\n",
    "        retainedpc = round((copied_images_count/total_images_count)*100,2)\n",
    "        print(f\" - Retained %:{retainedpc:.2f}\")\n",
    "  \n",
    "        # Update the copied image count for each job\n",
    "        copied_counts.append({'Job': job, 'Copied Images': copied_images_count})\n",
    "\n",
    "    # Merge counts into the original CSV and save it\n",
    "    counts_df = pd.DataFrame(copied_counts)\n",
    "    updated_df = csv_df.merge(counts_df, on='Job', how='left')\n",
    "    updated_df.to_csv(csv_file, index=False)\n",
    "\n",
    "# Load the CSV file with the thresholds for each job and specify the source and target folders. \n",
    "csv_file = 'Thresholds_for_SSIM_f_.csv'\n",
    "parent_folder = r'D:\\FlagDetectionDatasets\\ExportedDatasetsExtracted'\n",
    "destination_folder = r'D:\\FlagDetectionDatasets\\ExportedDatasetsExtractedStage2'\n",
    "\n",
    "#csv_file = 'Thresholds_for_SSIM_Round2Test.csv'\n",
    "#parent_folder = r'D:\\FlagDetectionDatasets\\ExportedDatasetsExtractedTest'\n",
    "#destination_folder = r'D:\\FlagDetectionDatasets\\ExportedDatasetsExtractedStage2'\n",
    "\n",
    "# Load the thresholds for each job and run compare images using SSIM \n",
    "thresholds, _ = load_thresholds_from_csv(csv_file)\n",
    "process_jobs(parent_folder, thresholds, destination_folder, csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f6e0ca-3c10-4bec-9803-53b9c774305d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
