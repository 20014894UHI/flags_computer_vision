{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d0cda30-b1e2-4e3b-a471-14fb3c8343f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Job 'Job_119' not found in thresholds. Skipping.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Job'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6228\\1653263936.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;31m# Load thresholds and process a specific job\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;31m# thresholds, _ = load_thresholds_from_csv(csv_file)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[0mjob_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Job_119\"\u001b[0m  \u001b[1;31m# These were the flags that are separated in this instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m \u001b[0mprocess_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestination_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.96\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6228\\1653263936.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(parent_folder, dest_folder, job, threshold)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mcopied_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Job'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Copied Images'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcopied_images_count\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;31m# Merge counts into the original CSV and save it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0mcounts_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopied_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[0mupdated_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Job'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m     \u001b[0mupdated_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10089\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10090\u001b[0m     ) -> DataFrame:\n\u001b[0;32m  10091\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10093\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m  10094\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10095\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10096\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0mindicator\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m ) -> DataFrame:\n\u001b[1;32m--> 110\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    699\u001b[0m         (\n\u001b[0;32m    700\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[1;31m# to avoid incompatible dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1158\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1162\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1163\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                 \u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[assignment]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m                 \u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m             )\n\u001b[0;32m   1849\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1850\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1853\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Job'"
     ]
    }
   ],
   "source": [
    "## Process jobs to filter image/annotation pairs using SSIM similarity threshold.\n",
    "## Simplified now to just do one job \n",
    "    \n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Function to load thresholds from CSV\n",
    "#def load_thresholds_from_csv(csv_file):\n",
    "    #df = pd.read_csv(csv_file)\n",
    "    #return {row['Job']: row['New threshold'] for _, row in df.iterrows() if str(row['Job']).startswith('Job_')}, df\n",
    "\n",
    "# Function to check if images are similar\n",
    "def is_similar(image1, image2, threshold):\n",
    "    if image1.shape != image2.shape:\n",
    "        return False\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    score, _ = ssim(gray1, gray2, full=True)\n",
    "    return score > threshold\n",
    "\n",
    "# Function to extract numeric part from filenames for sorting\n",
    "def extract_numeric_part(filename):\n",
    "    return int(''.join(filter(str.isdigit, filename)))\n",
    "\n",
    "# Function to process jobs\n",
    "def process_jobs(parent_folder, dest_folder, job, threshold):\n",
    "    \"\"\"\n",
    "    Process jobs to filter image/annotation pairs using SSIM similarity threshold.\n",
    "    \n",
    "    Args:\n",
    "        parent_folder (str): Path to the parent folder containing job subfolders.\n",
    "        threshold: threshold\n",
    "        dest_folder (str): Path to the destination folder.\n",
    "        job (str): job to process. \n",
    "    \"\"\"\n",
    "    _, csv_df = load_thresholds_from_csv(csv_file)\n",
    "    copied_counts = []\n",
    "\n",
    "    suffix = \"_SSIM\"\n",
    "\n",
    "    jobs_to_process = [job] if job else thresholds.keys()\n",
    "\n",
    "    for job in jobs_to_process:\n",
    "        if job not in thresholds:\n",
    "            print(f\"Error: Job '{job}' not found in thresholds. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        threshold = thresholds[job]\n",
    "        job_folder = os.path.join(parent_folder, job, 'obj_train_data')\n",
    "        output_folder = os.path.join(dest_folder, job + suffix, 'obj_train_data')\n",
    "\n",
    "        print(f\"Processing {job}:  threshold: {threshold}\")\n",
    "\n",
    "        # Skip job if target folder already contains images\n",
    "        if os.path.exists(output_folder) and len(os.listdir(output_folder)) > 0:\n",
    "            print(f\"Skipping {job} as images already exist in the target folder.\")\n",
    "            continue\n",
    "\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Get sorted list of image files in obj_train_data\n",
    "        image_files = sorted(\n",
    "            [f for f in os.listdir(job_folder) if f.lower().endswith(('.jpg', '.png'))],\n",
    "            key=extract_numeric_part\n",
    "        )\n",
    "\n",
    "        prev_image = None\n",
    "        copied_images_count = 0\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(job_folder, image_file)\n",
    "            text_path = os.path.splitext(image_path)[0] + '.txt'\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # Copy the first image and text file\n",
    "            if prev_image is None:\n",
    "                prev_image = image\n",
    "                shutil.copy(image_path, os.path.join(output_folder, image_file))\n",
    "                if os.path.exists(text_path):\n",
    "                    shutil.copy(text_path, os.path.join(output_folder, os.path.basename(text_path)))\n",
    "                copied_images_count += 1\n",
    "                continue\n",
    "\n",
    "            # Handle copy without comparison if threshold is NaN\n",
    "            if pd.isna(threshold):\n",
    "                shutil.copy(image_path, os.path.join(output_folder, image_file))\n",
    "                if os.path.exists(text_path):\n",
    "                    shutil.copy(text_path, os.path.join(output_folder, os.path.basename(text_path)))\n",
    "                copied_images_count += 1\n",
    "            else:\n",
    "                if not is_similar(prev_image, image, threshold):\n",
    "                    prev_image = image\n",
    "                    shutil.copy(image_path, os.path.join(output_folder, image_file))\n",
    "                    if os.path.exists(text_path):\n",
    "                        shutil.copy(text_path, os.path.join(output_folder, os.path.basename(text_path)))\n",
    "                    copied_images_count += 1\n",
    "\n",
    "        # Log the job and image counts\n",
    "        total_images_count = len(image_files)\n",
    "        print(f\"From Job '{job}':\")\n",
    "        print(f\" - Before processing : {total_images_count}\")\n",
    "        print(f\" - Filtered to {job + suffix} after processing: {copied_images_count}\")\n",
    "        retainedpc = round((copied_images_count / total_images_count) * 100, 2)\n",
    "        print(f\" - Retained %: {retainedpc:.2f}\")\n",
    "       \n",
    "        # Update the copied image count for each job\n",
    "        copied_counts.append({'Job': job, 'Copied Images': copied_images_count})\n",
    "\n",
    "    # Merge counts into the original CSV and save it\n",
    "    counts_df = pd.DataFrame(copied_counts)\n",
    "    updated_df = csv_df.merge(counts_df, on='Job', how='left')\n",
    "    updated_df.to_csv(csv_file, index=False)\n",
    "\n",
    "# Run it \n",
    "csv_file = 'ThresholdForSSIM_single.csv'\n",
    "parent_folder = r'D:\\FlagDetectionDatasets\\ExportedDatasetsReduced'\n",
    "destination_folder = r'D:\\FlagDetectionDatasets\\ExportedDatasetsReduced'\n",
    "\n",
    "# Load thresholds and process a specific job\n",
    "# thresholds, _ = load_thresholds_from_csv(csv_file)\n",
    "job_name = \"Job_119\"  # These were the flags that are separated in this instance \n",
    "process_jobs(parent_folder, destination_folder, job_name, 0.96)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00ce854-3023-48c9-994b-dbd59be75d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
