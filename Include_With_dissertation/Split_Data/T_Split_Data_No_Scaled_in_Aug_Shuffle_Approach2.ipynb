{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52c7cbc4-e890-41af-8f87-d40d36b240bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset split...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 164\u001b[0m\n\u001b[0;32m    161\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# Perform dataset split\u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m \u001b[43mbalance_dataset_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 107\u001b[0m, in \u001b[0;36mbalance_dataset_split\u001b[1;34m(source_folder, train_folder, test_folder, val_folder, log_file)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m augmented_folders:\n\u001b[0;32m    106\u001b[0m     pairs \u001b[38;5;241m=\u001b[39m find_pairs(folder)\n\u001b[1;32m--> 107\u001b[0m     \u001b[43mcopy_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     trainMoved \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(pairs)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMoved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainMoved\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m augmented pairs to train folder.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 62\u001b[0m, in \u001b[0;36mcopy_pairs\u001b[1;34m(pairs, dest_folder)\u001b[0m\n\u001b[0;32m     60\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(dest_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image, annotation \u001b[38;5;129;01min\u001b[39;00m pairs:\n\u001b[1;32m---> 62\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdest_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopy(annotation, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dest_folder, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(annotation)))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\flags\\lib\\shutil.py:418\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    417\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 418\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\flags\\lib\\shutil.py:282\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# Windows, see:\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# https://github.com/python/cpython/pull/7160#discussion_r195405230\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _WINDOWS \u001b[38;5;129;01mand\u001b[39;00m file_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 282\u001b[0m     \u001b[43m_copyfileobj_readinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfsrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOPY_BUFSIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dst\n\u001b[0;32m    285\u001b[0m copyfileobj(fsrc, fdst)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\flags\\lib\\shutil.py:195\u001b[0m, in \u001b[0;36m_copyfileobj_readinto\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    193\u001b[0m         fdst\u001b[38;5;241m.\u001b[39mwrite(smv)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 195\u001b[0m     \u001b[43mfdst_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmv\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Split a dataset into train, test, and validation sets balancing according to the logic below\n",
    "# NB All folders with \"Aug\" are NOT included in the augmentation SET\n",
    "# SHUFFLE NON -AUGMENTED DATA GLOBALLY Non augmented data is shuffled \n",
    "# All folders with \"Mrg\", \"Swapped\" and \"Perspective\" \"OCR\" only are incuded in the augmentation set. \n",
    "# Features:\n",
    "#- Identifies and moves augmented data to the train folder.\n",
    "#- Splits remaining data into train, test, and validation sets based on defined proportions.\n",
    "#- Logs details of the split into a CSV file for easy verification\n",
    "#\n",
    "#  Detailed outline: \n",
    "# 1.\tDefine split ratios as splitTrain .7, splitTest .15 and splitVal .15 1\n",
    "# 2.\tCalculate totalPairs (total dataset pairs) \n",
    "# 3.\tCalculate and augmentedPairs (pairs in augmented folders).\n",
    "# 4.\tCalculate the number of remaining pairs nonAugmentedPairs = totalPairs â€“ augmentedPairs)\n",
    "# 5.\tCalculate the targets to split the non-augmented data.\n",
    "#         o\tFor Train this will be totalPairs * splitTrain - augmentedPairs\n",
    "#         o\tFor Test this will be splitTest * totalPairs\n",
    "#         o\tFor Valid this will be splitVal * totalPairs\n",
    "# 6.\tCreate trainMoved, testMoved and valMoved to record the number moved for each set. \n",
    "# 7.\tMove the augmented data to the train folder, incrementing trainMoved\n",
    "# 8.\tConfirm that augmented data was moved to train folder and show value of trainMoved.\n",
    "# 9.\tShuffle the non -augmented data and distribute to 3 folders in a controlled way. \n",
    "        # o\t\n",
    "        # o\t\n",
    "        # o\t\n",
    "#10.\tContinue moving files to test until testMoved is equal to splitTest\n",
    "#11.\tContinue moving files to val until splitVal is equal to splitMoved\n",
    "#12.\tPrint a message when finished moving to test and when finished moving to val\n",
    "#13.\tMove the remaining unaugmented files to train, incrementing trainMoved\n",
    "#14.\tPrint a message when finished moving to train\n",
    "#15.\tCreate the CSV shwoing the number of pairs moved to each folder, the number of augmented folders moved to train \n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import csv\n",
    "\n",
    "def find_pairs(folder):\n",
    "    \"\"\"Find image/annotation pairs in a folder.\"\"\"\n",
    "    pairs = []\n",
    "    for root, _, files in os.walk(folder):\n",
    "        files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.txt'))]\n",
    "        images = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        for image in images:\n",
    "            annotation = os.path.splitext(image)[0] + \".txt\"\n",
    "            if annotation in files:\n",
    "                pairs.append((os.path.join(root, image), os.path.join(root, annotation)))\n",
    "    return pairs\n",
    "\n",
    "def copy_pairs(pairs, dest_folder):\n",
    "    \"\"\"Copy image/annotation pairs to a destination folder.\"\"\"\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "    for image, annotation in pairs:\n",
    "        shutil.copy(image, os.path.join(dest_folder, os.path.basename(image)))\n",
    "        shutil.copy(annotation, os.path.join(dest_folder, os.path.basename(annotation)))\n",
    "\n",
    "def balance_dataset_split(source_folder, train_folder, test_folder, val_folder, log_file):\n",
    "    \"\"\"Balance the dataset split into train, test, and validation sets.\"\"\"\n",
    "    splitTrain = 0.7\n",
    "    splitTest = 0.15\n",
    "    splitVal = 0.15\n",
    "\n",
    "    # Identify augmented folders\n",
    "    augmented_folders = [\n",
    "        os.path.join(source_folder, d)\n",
    "        for d in os.listdir(source_folder)\n",
    "        if os.path.isdir(os.path.join(source_folder, d)) and\n",
    "        (\"Mrg\" in d or \"Swapped\" in d or \"Perspective\" in d or \"OCR\" in d)\n",
    "    ]\n",
    "\n",
    "    # Identify non-augmented folders (all other folders)\n",
    "    non_augmented_folders = [\n",
    "        os.path.join(source_folder, d)\n",
    "        for d in os.listdir(source_folder)\n",
    "        if os.path.isdir(os.path.join(source_folder, d)) and\n",
    "        d not in {os.path.basename(folder) for folder in augmented_folders}\n",
    "    ]\n",
    "\n",
    "    log_data = []\n",
    "\n",
    "    # Collect all pairs and calculate dataset statistics\n",
    "    totalPairs = 0\n",
    "    augmentedPairs = 0\n",
    "    all_non_augmented_pairs = []\n",
    "\n",
    "    # Process augmented folders\n",
    "    for folder in augmented_folders:\n",
    "        pairs = find_pairs(folder)\n",
    "        totalPairs += len(pairs)\n",
    "        augmentedPairs += len(pairs)\n",
    "        copy_pairs(pairs, train_folder)\n",
    "        log_data.append([os.path.basename(folder), len(pairs), len(pairs), 0, 0])  # Log augmented folders\n",
    "\n",
    "    # Process non-augmented folders\n",
    "    for folder in non_augmented_folders:\n",
    "        pairs = find_pairs(folder)\n",
    "        totalPairs += len(pairs)\n",
    "        all_non_augmented_pairs.extend(pairs)\n",
    "        log_data.append([os.path.basename(folder), len(pairs), 0, 0, 0])  # Initialize log entry\n",
    "\n",
    "    nonAugmentedPairs = totalPairs - augmentedPairs\n",
    "    trainTarget = int(totalPairs * splitTrain) - augmentedPairs\n",
    "    testTarget = int(totalPairs * splitTest)\n",
    "    valTarget = int(totalPairs * splitVal)\n",
    "\n",
    "    # Shuffle non-augmented pairs globally\n",
    "    random.shuffle(all_non_augmented_pairs)\n",
    "\n",
    "    trainMoved, testMoved, valMoved = 0, 0, 0\n",
    "\n",
    "    # Allocate non-augmented data to test, validation, and train\n",
    "    for pair in all_non_augmented_pairs:\n",
    "        if testMoved < testTarget:\n",
    "            copy_pairs([pair], test_folder)\n",
    "            testMoved += 1\n",
    "        elif valMoved < valTarget:\n",
    "            copy_pairs([pair], val_folder)\n",
    "            valMoved += 1\n",
    "        else:\n",
    "            copy_pairs([pair], train_folder)\n",
    "            trainMoved += 1\n",
    "\n",
    "    # Update log with final counts\n",
    "    for row in log_data:\n",
    "        folder_name = row[0]\n",
    "        folder_pairs = [p for p in all_non_augmented_pairs if folder_name in p[0]]\n",
    "        row[2] += len([p for p in folder_pairs if p in train_folder])\n",
    "        row[3] += len([p for p in folder_pairs if p in test_folder])\n",
    "        row[4] += len([p for p in folder_pairs if p in val_folder])\n",
    "\n",
    "    # Add summary to log\n",
    "    log_data.append([\n",
    "        \"TOTAL\", totalPairs, trainMoved, testMoved, valMoved\n",
    "    ])\n",
    "\n",
    "    print(f\"Finished moving data: {trainMoved} to train, {testMoved} to test, {valMoved} to val.\")\n",
    "\n",
    "    # Save log to CSV\n",
    "    with open(log_file, mode='w', newline='') as csvfile:\n",
    "        log_writer = csv.writer(csvfile)\n",
    "        log_writer.writerow([\"Subfolder\", \"Total Pairs\", \"Train Moved\", \"Test Moved\", \"Val Moved\"])\n",
    "        log_writer.writerows(log_data)\n",
    "\n",
    "    print(f\"Log saved to {log_file}.\")\n",
    "    print(f\"Total Pairs: {totalPairs}, Augmented Pairs: {augmentedPairs}, Non-Augmented Pairs: {nonAugmentedPairs}\")\n",
    "\n",
    "\n",
    "# Define source and target folders\n",
    "source_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsSelectedML\"\n",
    "train_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsSelectedMLSHUFFLE/train\"\n",
    "test_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsSelectedMLSHUFFLE/test\"\n",
    "val_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsSelectedMLSHUFFLE/val\"\n",
    "log_file = \"split_log_shuffle.csv\"\n",
    "\n",
    "# Create train, test, and validation folders\n",
    "for folder in [train_folder, test_folder, val_folder]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Balance dataset split\n",
    "balance_dataset_split(source_folder, train_folder, test_folder, val_folder, log_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eae83a-d3e1-4137-92c3-6761b90713a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
