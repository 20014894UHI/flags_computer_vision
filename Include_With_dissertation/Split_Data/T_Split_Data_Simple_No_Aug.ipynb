{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c7cbc4-e890-41af-8f87-d40d36b240bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset split...\n",
      "Moved 0 augmented pairs to train folder.\n",
      "Finished moving data: 8461 to train, 1813 to test, 1813 to val.\n",
      "Log saved to split_log_13.csv.\n",
      "Total Pairs: 12087, Augmented Pairs: 0, Non-Augmented Pairs: 12087\n"
     ]
    }
   ],
   "source": [
    "# Split a dataset into train, test, and validation sets balancing according to the logic below\n",
    "# THERE IS NO LOGIC FOR SEPARATNG AUGMETNED FILES HERE SIMPLE SPLIT IN ROUND ROBIN STYLE\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import random\n",
    "\n",
    "def find_pairs(folder):\n",
    "    \"\"\"Find image/annotation pairs in a folder.\"\"\"\n",
    "    pairs = []\n",
    "    for root, _, files in os.walk(folder):\n",
    "        files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.txt'))]\n",
    "        images = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        for image in images:\n",
    "            annotation = os.path.splitext(image)[0] + \".txt\"\n",
    "            if annotation in files:\n",
    "                pairs.append((os.path.join(root, image), os.path.join(root, annotation)))\n",
    "    return pairs\n",
    "\n",
    "def copy_pairs(pairs, dest_folder):\n",
    "    \"\"\"Copy image/annotation pairs to a destination folder.\"\"\"\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "    for image, annotation in pairs:\n",
    "        shutil.copy(image, os.path.join(dest_folder, os.path.basename(image)))\n",
    "        shutil.copy(annotation, os.path.join(dest_folder, os.path.basename(annotation)))\n",
    "\n",
    "def split_dataset(source_folder, train_folder, val_folder, test_folder, log_file, train_ratio=0.7, val_ratio=0.15):\n",
    "    \"\"\"Split dataset into train, validation, and test sets using round-robin allocation.\"\"\"\n",
    "    print(\"Starting dataset split...\")\n",
    "    \n",
    "    # Find all pairs in the source folder\n",
    "    all_pairs = []\n",
    "    for subfolder in os.listdir(source_folder):\n",
    "        folder_path = os.path.join(source_folder, subfolder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            pairs = find_pairs(folder_path)\n",
    "            all_pairs.extend(pairs)\n",
    "\n",
    "    # Shuffle all pairs\n",
    "    random.shuffle(all_pairs)\n",
    "\n",
    "    # Calculate split counts\n",
    "    total_pairs = len(all_pairs)\n",
    "    train_count = int(total_pairs * train_ratio)\n",
    "    val_count = int(total_pairs * val_ratio)\n",
    "    test_count = total_pairs - train_count - val_count\n",
    "\n",
    "    # Split data\n",
    "    train_pairs = all_pairs[:train_count]\n",
    "    val_pairs = all_pairs[train_count:train_count + val_count]\n",
    "    test_pairs = all_pairs[train_count + val_count:]\n",
    "\n",
    "    # Copy pairs to respective folders\n",
    "    copy_pairs(train_pairs, train_folder)\n",
    "    copy_pairs(val_pairs, val_folder)\n",
    "    copy_pairs(test_pairs, test_folder)\n",
    "\n",
    "    # Log results\n",
    "    with open(log_file, mode='w', newline='') as csvfile:\n",
    "        log_writer = csv.writer(csvfile)\n",
    "        log_writer.writerow([\"Total Pairs\", \"Train Pairs\", \"Validation Pairs\", \"Test Pairs\"])\n",
    "        log_writer.writerow([total_pairs, train_count, val_count, test_count])\n",
    "\n",
    "    print(f\"Dataset split completed. Train: {train_count}, Validation: {val_count}, Test: {test_count}. Log saved to {log_file}.\")\n",
    "\n",
    "# Define paths\n",
    "source_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsReducedML\"\n",
    "train_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsReducedML_A/train\"\n",
    "val_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsReducedML_A/val\"\n",
    "test_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsReducedML_A/test\"\n",
    "log_file = \"split_log_simplified.csv\"\n",
    "\n",
    "# Create train, validation, and test folders\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(val_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# Split dataset\n",
    "split_dataset(source_folder, train_folder, val_folder, test_folder, log_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eae83a-d3e1-4137-92c3-6761b90713a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
