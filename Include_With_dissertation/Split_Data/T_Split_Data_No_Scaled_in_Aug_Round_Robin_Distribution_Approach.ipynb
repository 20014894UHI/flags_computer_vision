{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52c7cbc4-e890-41af-8f87-d40d36b240bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset split...\n",
      "Moved 185 augmented pairs to train folder.\n",
      "Finished moving data: 6127 to train, 1312 to test, 1312 to val.\n",
      "Log saved to split_log_11_1_25.csv.\n",
      "Total Pairs: 8751, Augmented Pairs: 185, Non-Augmented Pairs: 8566\n"
     ]
    }
   ],
   "source": [
    "# Split a dataset into train, test, and validation sets balancing according to the logic below\n",
    "# NB All folders with \"Aug\" are NOT included in the augmentation SET\n",
    "# All folders with \"Mrg\", \"Swapped\" and \"Perspective\" only are incuded in the augmentation set. \n",
    "# Features:\n",
    "#- Identifies and moves augmented data to the train folder.\n",
    "#- Splits remaining data into train, test, and validation sets based on defined proportions.\n",
    "#- Logs details of the split into a CSV file for easy verification\n",
    "#\n",
    "#  Detailed outline: \n",
    "# 1.\tDefine split ratios as splitTrain .7, splitTest .15 and splitVal .15 1\n",
    "# 2.\tCalculate totalPairs (total dataset pairs) \n",
    "# 3.\tCalculate and augmentedPairs (pairs in augmented folders).\n",
    "# 4.\tCalculate the number of remaining pairs nonAugmentedPairs = totalPairs â€“ augmentedPairs)\n",
    "# 5.\tCalculate the targets to split the non-augmented data.\n",
    "#         o\tFor Train this will be totalPairs * splitTrain - augmentedPairs\n",
    "#         o\tFor Test this will be splitTest * totalPairs\n",
    "#         o\tFor Valid this will be splitVal * totalPairs\n",
    "# 6.\tCreate trainMoved, testMoved and valMoved to record the number moved for each set. \n",
    "# 7.\tMove the augmented data to the train folder, incrementing trainMoved\n",
    "# 8.\tConfirm that augmented data was moved to train folder and show value of trainMoved.\n",
    "# 9.\tSplit the remaining data into the 3 folders in a controlled way. For each sub-folder\n",
    "        # o\tMove 1 pair to test and increment testMoved\n",
    "        # o\tMove 1 pair to val and increment valMoved\n",
    "        # o\tMove 1 pair to trainMoved and increment trainMoved\n",
    "#10.\tContinue moving files to test until testMoved is equal to splitTest\n",
    "#11.\tContinue moving files to val until splitVal is equal to splitMoved\n",
    "#12.\tPrint a message when finished moving to test and when finished moving to val\n",
    "#13.\tMove the remaining unaugmented files to train, incrementing trainMoved\n",
    "#14.\tPrint a message when finished moving to train\n",
    "#15.\tCreate the CSV shwoing the number of pairs moved to each folder, the number of augmented folders moved to train \n",
    "#       Consider these edge cases and consider also the viability of the resulting split and overall balance of unaugmented data in train\n",
    "#       Is it sufficient, etc. Scenario where augmented data is equal or greater than the allowed allocation for the train split (augmentedPairs >= totalPairs * splitTrain)\n",
    "#\t    All remaining non-augmented pairs will go to test and val only\n",
    "#       Scenario where remaining non augmented data is less than than the target for both test and val (nonAugmentedPairs < testTarget + valTarget)\n",
    "#\t    adjust the allocation to ensure no excess or shortage in test and val.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import csv\n",
    "\n",
    "def find_pairs(folder):\n",
    "    \"\"\"Find image/annotation pairs in a folder.\"\"\"\n",
    "    pairs = []\n",
    "    for root, _, files in os.walk(folder):\n",
    "        files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.txt'))]\n",
    "        images = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        for image in images:\n",
    "            annotation = os.path.splitext(image)[0] + \".txt\"\n",
    "            if annotation in files:\n",
    "                pairs.append((os.path.join(root, image), os.path.join(root, annotation)))\n",
    "    return pairs\n",
    "\n",
    "def copy_pairs(pairs, dest_folder):\n",
    "    \"\"\"Copy image/annotation pairs to a destination folder.\"\"\"\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "    for image, annotation in pairs:\n",
    "        shutil.copy(image, os.path.join(dest_folder, os.path.basename(image)))\n",
    "        shutil.copy(annotation, os.path.join(dest_folder, os.path.basename(annotation)))\n",
    "\n",
    "def balance_dataset_split(source_folder, train_folder, test_folder, val_folder, log_file):\n",
    "    \"\"\"Balance the dataset split into train, test, and validation sets.\"\"\"\n",
    "    print(\"Starting dataset split...\")\n",
    "\n",
    "    # Define split ratios\n",
    "    splitTrain = 0.7\n",
    "    splitTest = 0.15\n",
    "    splitVal = 0.15\n",
    "\n",
    "    # Identify augmented folders\n",
    "    augmented_folders = [\n",
    "        os.path.join(source_folder, d)\n",
    "        for d in os.listdir(source_folder)\n",
    "        if os.path.isdir(os.path.join(source_folder, d)) and\n",
    "        (\"Mrg\" in d or \"Swapped\" in d or \"Perspective\" in d or \"OCR\" in d)\n",
    "    ]\n",
    "    \n",
    "    # Identify non-augmented folders (all other folders)\n",
    "    non_augmented_folders = [\n",
    "        os.path.join(source_folder, d)\n",
    "        for d in os.listdir(source_folder)\n",
    "        if os.path.isdir(os.path.join(source_folder, d)) and\n",
    "        os.path.join(source_folder, d) not in augmented_folders\n",
    "    ]\n",
    "\n",
    "    log_data = []\n",
    "\n",
    "    # Calculate dataset statistics\n",
    "    totalPairs = sum(len(find_pairs(folder)) for folder in augmented_folders + non_augmented_folders)\n",
    "    augmentedPairs = sum(len(find_pairs(folder)) for folder in augmented_folders)\n",
    "    nonAugmentedPairs = totalPairs - augmentedPairs\n",
    "\n",
    "    # Calculate targets for train, test, and validation\n",
    "    trainTarget = int(totalPairs * splitTrain) - augmentedPairs\n",
    "    testTarget = int(totalPairs * splitTest)\n",
    "    valTarget = int(totalPairs * splitVal)\n",
    "\n",
    "    trainMoved, testMoved, valMoved = 0, 0, 0\n",
    "\n",
    "    # Step 7: Move augmented data to train folder\n",
    "    for folder in augmented_folders:\n",
    "        pairs = find_pairs(folder)\n",
    "        copy_pairs(pairs, train_folder)\n",
    "        trainMoved += len(pairs)\n",
    "\n",
    "        # Add augmented folder to log\n",
    "        folder_name = os.path.basename(folder)\n",
    "        log_data.append([folder_name, len(pairs), len(pairs), 0, 0])\n",
    "\n",
    "    print(f\"Moved {trainMoved} augmented pairs to train folder.\")\n",
    "\n",
    "    # Step 9: Split non-augmented data in a round-robin manner\n",
    "    non_augmented_pairs_by_folder = {folder: find_pairs(folder) for folder in non_augmented_folders}\n",
    "    \n",
    "    # Allocate in a round-robin manner\n",
    "    while any(non_augmented_pairs_by_folder.values()):\n",
    "        for folder, pairs in list(non_augmented_pairs_by_folder.items()):\n",
    "            if not pairs:\n",
    "                continue  # Skip if no more pairs in this folder\n",
    "\n",
    "            pair = pairs.pop(0)  # Get the first pair\n",
    "            folder_name = os.path.basename(folder)\n",
    "\n",
    "            if testMoved < testTarget:\n",
    "                copy_pairs([pair], test_folder)\n",
    "                testMoved += 1\n",
    "\n",
    "                # Update log_data\n",
    "                log_entry = next((row for row in log_data if row[0] == folder_name), None)\n",
    "                if not log_entry:\n",
    "                    log_data.append([folder_name, len(find_pairs(folder)), 0, 0, 0])\n",
    "                    log_entry = log_data[-1]\n",
    "                log_entry[3] += 1  # Increment test moved\n",
    "            elif valMoved < valTarget:\n",
    "                copy_pairs([pair], val_folder)\n",
    "                valMoved += 1\n",
    "\n",
    "                # Update log_data\n",
    "                log_entry = next((row for row in log_data if row[0] == folder_name), None)\n",
    "                if not log_entry:\n",
    "                    log_data.append([folder_name, len(find_pairs(folder)), 0, 0, 0])\n",
    "                    log_entry = log_data[-1]\n",
    "                log_entry[4] += 1  # Increment val moved\n",
    "            else:\n",
    "                copy_pairs([pair], train_folder)\n",
    "                trainMoved += 1\n",
    "\n",
    "                # Update log_data\n",
    "                log_entry = next((row for row in log_data if row[0] == folder_name), None)\n",
    "                if not log_entry:\n",
    "                    log_data.append([folder_name, len(find_pairs(folder)), 0, 0, 0])\n",
    "                    log_entry = log_data[-1]\n",
    "                log_entry[2] += 1  # Increment train moved\n",
    "\n",
    "            # Remove empty folders from the dictionary\n",
    "            if not pairs:\n",
    "                del non_augmented_pairs_by_folder[folder]\n",
    "\n",
    "    print(f\"Finished moving data: {trainMoved} to train, {testMoved} to test, {valMoved} to val.\")\n",
    "\n",
    "    # Create CSV log\n",
    "    with open(log_file, mode='w', newline='') as csvfile:\n",
    "        log_writer = csv.writer(csvfile)\n",
    "        log_writer.writerow([\n",
    "            \"Subfolder\", \"Total Pairs\", \"Train Moved\", \"Test Moved\", \"Val Moved\"\n",
    "        ])\n",
    "        log_writer.writerows(log_data)\n",
    "\n",
    "    print(f\"Log saved to {log_file}.\")\n",
    "    print(f\"Total Pairs: {totalPairs}, Augmented Pairs: {augmentedPairs}, Non-Augmented Pairs: {nonAugmentedPairs}\")\n",
    "\n",
    "\n",
    "# Source and target folders\n",
    "source_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsSelectedML\"\n",
    "train_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsSelectedMLROBIN/train\"\n",
    "test_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsSelectedMLROBIN/test\"\n",
    "val_folder = \"D:/FlagDetectionDatasets/ExportedDatasetsSelectedMLROBIN/val\"\n",
    "log_file = \"split_log_11_1_25.csv\"\n",
    "\n",
    "# Create train, test, and validation folders\n",
    "for folder in [train_folder, test_folder, val_folder]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Split it  \n",
    "balance_dataset_split(source_folder, train_folder, test_folder, val_folder, log_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eae83a-d3e1-4137-92c3-6761b90713a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
