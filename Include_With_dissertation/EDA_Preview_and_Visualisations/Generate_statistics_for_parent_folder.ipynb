{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b8bb3cb-5002-4aea-8d1b-16d17d807016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/FlagDetectionDatasets/ExportedDatasetsReduced/obj.names\n",
      "No job folders found in D:/FlagDetectionDatasets/ExportedDatasetsSelectedMLROBIN. Exiting.\n"
     ]
    }
   ],
   "source": [
    "# count_selected() expects the data in Job subfolders as it sorts them by the numeric part \n",
    "# count_selected_flat () is suitable for the dataset once it has been split e.g. parent > train, test, val \n",
    "\"\"\"\n",
    "Script Name: Job Folder Statistics Generator\n",
    "Description: This script processes a parent folder containing subfolders (jobs) and generates a CSV report \n",
    "             with detailed statistics about images and annotations in each subfolder. It also verifies the \n",
    "             presence of image-annotation pairs and counts class occurrences.\n",
    "\n",
    "Features:\n",
    "    - Reads class names from an `obj.names` file.\n",
    "    - Handles subfolders that may contain an `obj_train_data` folder or directly contain images and annotations.\n",
    "    - Calculates total statistics across all job folders.\n",
    "    - Logs any problematic files or folders.\n",
    "\n",
    "Input:\n",
    "    - Parent folder containing job subfolders (e.g., `Job_1`, `Job_2`, etc.).\n",
    "    - Each job folder may contain:\n",
    "        - Images (.png, .jpg, .jpeg).\n",
    "        - Annotations (.txt files).\n",
    "        - Optionally, a subfolder named `obj_train_data`.\n",
    "\n",
    "Output:\n",
    "    - A CSV file summarizing statistics for each job folder, including:\n",
    "        - Job name.\n",
    "        - Number of images and annotations.\n",
    "        - Whether all image-annotation pairs are present.\n",
    "        - Class-wise counts.\n",
    "\n",
    "Dependencies:\n",
    "    - Python 3\n",
    "    - Libraries: os, re, pandas, collections.defaultdict\n",
    "\"\"\"\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def read_classes_from_file(file_path):\n",
    "    \"\"\"Read class names from a file.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return []\n",
    "    with open(file_path, 'r') as f:\n",
    "        return [line.strip() for line in f.readlines()]\n",
    "\n",
    "def count_selected_flat(parent_folder, output_csv=\"job_statistics_selected.csv\"):\n",
    "    \"\"\"\n",
    "    Process folders to generate a CSV with job statistics, while handling folders\n",
    "    that do not match the expected naming pattern.\n",
    "\n",
    "    Args:\n",
    "        parent_folder (str): Path to the parent folder.\n",
    "        output_csv (str): Path to save the CSV file with job statistics.\n",
    "    \"\"\"\n",
    "    def extract_job_number(folder_name):\n",
    "        \"\"\"Extract the job number from the folder name.\"\"\"\n",
    "        match = re.search(r'_(\\d+)', folder_name)\n",
    "        return int(match.group(1)) if match else None\n",
    "\n",
    "    print (obj_names_path)\n",
    "    classes = read_classes_from_file(obj_names_path)\n",
    "    if not classes:\n",
    "        print(\"No classes found in obj.names. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Get and sort job folders\n",
    "    job_folders = [\n",
    "        f.path for f in os.scandir(parent_folder) if f.is_dir()\n",
    "    ]\n",
    "    job_folders = [folder for folder, _ in job_folders]\n",
    "\n",
    "    if not job_folders:\n",
    "        print(f\"No folders found in {parent_folder}. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Process the folders\n",
    "    data = []\n",
    "    skipped_files = []  # To log problematic files\n",
    "\n",
    "    for job_folder in job_folders:\n",
    "        job_name = os.path.basename(job_folder)\n",
    "\n",
    "        obj_train_data_folder = os.path.join(job_folder, \"obj_train_data\")\n",
    "        image_folder = obj_train_data_folder if os.path.exists(obj_train_data_folder) else job_folder\n",
    "\n",
    "        images = [\n",
    "            f for f in os.listdir(image_folder)\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ]\n",
    "        annotations = [\n",
    "            f for f in os.listdir(image_folder)\n",
    "            if f.lower().endswith('.txt')\n",
    "        ]\n",
    "\n",
    "        image_count = len(images)\n",
    "        annotation_count = len(annotations)\n",
    "\n",
    "        # Calculate total size of images\n",
    "        total_image_size = sum(\n",
    "            os.path.getsize(os.path.join(image_folder, img)) for img in images\n",
    "        ) / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "        # Check if all image/annotation pairs are present\n",
    "        all_pairs_present = all(\n",
    "            os.path.exists(os.path.join(image_folder, os.path.splitext(img)[0] + \".txt\"))\n",
    "            for img in images\n",
    "        )\n",
    "\n",
    "        # Count classes in annotations\n",
    "        class_counts = defaultdict(int)\n",
    "        for annotation in annotations:\n",
    "            try:\n",
    "                with open(os.path.join(image_folder, annotation), 'r') as file:\n",
    "                    for line in file:\n",
    "                        class_id = int(line.split()[0])\n",
    "                        class_counts[f\"{class_id}\"] += 1\n",
    "            except (ValueError, IndexError) as e:\n",
    "                skipped_files.append((job_folder, annotation, str(e)))\n",
    "\n",
    "        # Prepare data for CSV\n",
    "        row = {\n",
    "            \"Folder Name\": job_name,\n",
    "            \"Image Count\": image_count,\n",
    "            \"Annotation Count\": annotation_count,\n",
    "            \"Total Image Size (MB)\": round(total_image_size, 2),\n",
    "            \"All Image/Annotation Pairs Present\": all_pairs_present,\n",
    "        }\n",
    "        for i, cls in enumerate(classes):\n",
    "            row[cls] = class_counts.get(str(i), 0)\n",
    "        data.append(row)\n",
    "\n",
    "    # Calculate totals\n",
    "    total_image_size_mb = sum(row[\"Total Image Size (MB)\"] for row in data)\n",
    "    total_image_size_gb = total_image_size_mb / 1024\n",
    "    totals = {\n",
    "        \"Folder Name\": \"TOTAL\",\n",
    "        \"Image Count\": sum(row[\"Image Count\"] for row in data),\n",
    "        \"Annotation Count\": sum(row[\"Annotation Count\"] for row in data),\n",
    "        \"Total Image Size (MB)\": f\"{round(total_image_size_mb, 2)} MB ({round(total_image_size_gb, 2)} GB)\",\n",
    "        \"All Image/Annotation Pairs Present\": \"\",\n",
    "    }\n",
    "    for cls in classes:\n",
    "        totals[cls] = sum(row[cls] for row in data)\n",
    "    data.append(totals)\n",
    "\n",
    "    # Write data to CSV\n",
    "    header = [\n",
    "        \"Folder Name\", \"Image Count\", \"Annotation Count\", \"Total Image Size (MB)\", \"All Image/Annotation Pairs Present\"\n",
    "    ] + classes\n",
    "    df = pd.DataFrame(data, columns=header)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"CSV file created: {output_csv}\")\n",
    "\n",
    "    # Log skipped files\n",
    "    if skipped_files:\n",
    "        print(\"\\nSkipped files due to errors:\")\n",
    "        for job_folder, annotation, error in skipped_files:\n",
    "            print(f\"Job: {job_folder}, File: {annotation}, Error: {error}\")\n",
    "\n",
    "# Used this when data is in Job_No folders - up to the stage of splitting the data \n",
    "def count_selected(parent_folder, output_csv=\"job_statistics_selected.csv\"):\n",
    "    \"\"\"\n",
    "    Process folders to generate a CSV with job statistics, while handling folders\n",
    "    that do not match the expected naming pattern.\n",
    "\n",
    "    Args:\n",
    "        parent_folder (str): Path to the parent folder.\n",
    "        output_csv (str): Path to save the CSV file with job statistics.\n",
    "    \"\"\"\n",
    "    def extract_job_number(folder_name):\n",
    "        \"\"\"Extract the job number from the folder name.\"\"\"\n",
    "        match = re.search(r'_(\\d+)', folder_name)\n",
    "        return int(match.group(1)) if match else None\n",
    "\n",
    "    # Read class names from obj.names\n",
    "    # obj_names_path = os.path.normpath(os.path.join(parent_folder, \"obj.names\"))\n",
    "    # obj_names_path = os.path.join(parent_folder, \"obj.names\")\n",
    "    print (obj_names_path)\n",
    "    classes = read_classes_from_file(obj_names_path)\n",
    "    if not classes:\n",
    "        print(\"No classes found in obj.names. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Get and sort job folders\n",
    "    job_folders = [\n",
    "        f.path for f in os.scandir(parent_folder) if f.is_dir()\n",
    "    ]\n",
    "    job_folders_with_numbers = [\n",
    "        (folder, extract_job_number(os.path.basename(folder))) for folder in job_folders\n",
    "    ]\n",
    "    job_folders_with_numbers = [\n",
    "        (folder, num) for folder, num in job_folders_with_numbers if num is not None\n",
    "    ]\n",
    "    job_folders_with_numbers.sort(key=lambda x: x[1])  # Sort by extracted number\n",
    "    job_folders = [folder for folder, _ in job_folders_with_numbers]\n",
    "\n",
    "    if not job_folders:\n",
    "        print(f\"No job folders found in {parent_folder}. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Process the folders\n",
    "    data = []\n",
    "    skipped_files = []  # To log problematic files\n",
    "\n",
    "    for job_folder in job_folders:\n",
    "        job_name = os.path.basename(job_folder)\n",
    "\n",
    "        obj_train_data_folder = os.path.join(job_folder, \"obj_train_data\")\n",
    "        image_folder = obj_train_data_folder if os.path.exists(obj_train_data_folder) else job_folder\n",
    "\n",
    "        images = [\n",
    "            f for f in os.listdir(image_folder)\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ]\n",
    "        annotations = [\n",
    "            f for f in os.listdir(image_folder)\n",
    "            if f.lower().endswith('.txt')\n",
    "        ]\n",
    "\n",
    "        image_count = len(images)\n",
    "        annotation_count = len(annotations)\n",
    "\n",
    "        # Calculate total size of images\n",
    "        total_image_size = sum(\n",
    "            os.path.getsize(os.path.join(image_folder, img)) for img in images\n",
    "        ) / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "        # Check if all image/annotation pairs are present\n",
    "        all_pairs_present = all(\n",
    "            os.path.exists(os.path.join(image_folder, os.path.splitext(img)[0] + \".txt\"))\n",
    "            for img in images\n",
    "        )\n",
    "\n",
    "        # Count classes in annotations\n",
    "        class_counts = defaultdict(int)\n",
    "        for annotation in annotations:\n",
    "            try:\n",
    "                with open(os.path.join(image_folder, annotation), 'r') as file:\n",
    "                    for line in file:\n",
    "                        class_id = int(line.split()[0])\n",
    "                        class_counts[f\"{class_id}\"] += 1\n",
    "            except (ValueError, IndexError) as e:\n",
    "                skipped_files.append((job_folder, annotation, str(e)))\n",
    "\n",
    "        # Prepare data for CSV\n",
    "        row = {\n",
    "            \"Job Name\": job_name,\n",
    "            \"Image Count\": image_count,\n",
    "            \"Annotation Count\": annotation_count,\n",
    "            \"Total Image Size (MB)\": round(total_image_size, 2),\n",
    "            \"All Image/Annotation Pairs Present\": all_pairs_present,\n",
    "        }\n",
    "        for i, cls in enumerate(classes):\n",
    "            row[cls] = class_counts.get(str(i), 0)\n",
    "        data.append(row)\n",
    "\n",
    "    # Calculate totals\n",
    "    total_image_size_mb = sum(row[\"Total Image Size (MB)\"] for row in data)\n",
    "    total_image_size_gb = total_image_size_mb / 1024\n",
    "    totals = {\n",
    "        \"Job Name\": \"TOTAL\",\n",
    "        \"Image Count\": sum(row[\"Image Count\"] for row in data),\n",
    "        \"Annotation Count\": sum(row[\"Annotation Count\"] for row in data),\n",
    "        \"Total Image Size (MB)\": f\"{round(total_image_size_mb, 2)} MB ({round(total_image_size_gb, 2)} GB)\",\n",
    "        \"All Image/Annotation Pairs Present\": \"\",\n",
    "    }\n",
    "    for cls in classes:\n",
    "        totals[cls] = sum(row[cls] for row in data)\n",
    "    data.append(totals)\n",
    "\n",
    "    # Write data to CSV\n",
    "    header = [\n",
    "        \"Job Name\", \"Image Count\", \"Annotation Count\", \"Total Image Size (MB)\", \"All Image/Annotation Pairs Present\"\n",
    "    ] + classes\n",
    "    df = pd.DataFrame(data, columns=header)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"CSV file created: {output_csv}\")\n",
    "\n",
    "    # Log skipped files\n",
    "    if skipped_files:\n",
    "        print(\"\\nSkipped files due to errors:\")\n",
    "        for job_folder, annotation, error in skipped_files:\n",
    "            print(f\"Job: {job_folder}, File: {annotation}, Error: {error}\")\n",
    "\n",
    "#===================================================================================================================================#\n",
    "obj_names_path = 'D:/FlagDetectionDatasets/ExportedDatasetsReduced/obj.names'\n",
    "\n",
    "#parent_folder = 'D:/FlagDetectionDatasets/ExportedDatasetsExtracted'\n",
    "#output_csv = \"job_statistics_data_export_from_cvat.csv\"\n",
    "#count_selected(parent_folder, output_csv)\n",
    "\n",
    "#parent_folder = 'D:/FlagDetectionDatasets/ExportedDatasetsReduced'\n",
    "#output_csv = \"job_statistics_reduced_dataset1.csv\"\n",
    "#count_selected(parent_folder, output_csv)\n",
    "\n",
    "#parent_folder = 'D:/FlagDetectionDatasets/ExportedDatasetsSelectedML'\n",
    "#output_csv = \"job_statistics_selected_ML.csv\"\n",
    "#count_selected(parent_folder, output_csv)\n",
    "\n",
    "parent_folder = 'D:/FlagDetectionDatasets/ExportedDatasetsSelectedMLROBIN'\n",
    "output_csv = \"job_statistics_selected_MLROBIN.csv\"\n",
    "count_selected(parent_folder, output_csv)\n",
    "\n",
    "#parent_folder = 'D:/FlagDetectionDatasets/ExportedDatasetsReduced'\n",
    "#output_csv = \"job_statistics_reduced.csv\"\n",
    "\n",
    "#parent_folder = 'D:/FlagDetectionDatasets/ExportedDatasetsReduced'\n",
    "#output_csv = \"job_statistics_reduced_dataset1.csv\"\n",
    "#count_selected(parent_folder, output_csv)\n",
    "\n",
    "#count_selected(parent_folder, output_csv)\n",
    "\n",
    "# Count images in datasets\n",
    "#parent_folder = r'D:\\FlagDetectionDatasets\\ExportedDatasetsReduced'\n",
    "#output_csv = \"csv\\image_counts_by_job4.csv\"\n",
    "#output_csv = \"image_counts_and_classes.csv\"  # Output CSV file\n",
    "#count_images_and_classes(parent_folder, output_csv)\n",
    "\n",
    "#process_job_folders(folder_path, output_csv, image_subfolder_name=\"obj_train_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f377bfbf-3921-4025-8516-8c006c11cac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
