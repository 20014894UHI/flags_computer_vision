{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5635d22a-6676-444e-9aeb-3d68fbaf633a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (1068,134,3) into shape (893,134,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 107\u001b[0m\n\u001b[0;32m    104\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFlagDetectionDatasets\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mExportedTaskDatasetsZips\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mJob_73\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mJob_73_scaled\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m scale_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.5\u001b[39m\n\u001b[1;32m--> 107\u001b[0m \u001b[43mprocess_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotations_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 88\u001b[0m, in \u001b[0;36mprocess_folder\u001b[1;34m(images_folder, annotations_folder, output_folder, scale_factor)\u001b[0m\n\u001b[0;32m     86\u001b[0m new_annotations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m annotations:\n\u001b[1;32m---> 88\u001b[0m     image, new_bbox \u001b[38;5;241m=\u001b[39m \u001b[43mscale_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     new_annotations\u001b[38;5;241m.\u001b[39mappend(new_bbox)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Save the updated image and annotation\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 46\u001b[0m, in \u001b[0;36mscale_object\u001b[1;34m(image, bbox, scale_factor)\u001b[0m\n\u001b[0;32m     43\u001b[0m new_y2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(h, new_y2)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Paste the resized object back into the image\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m image[new_y1:new_y2, new_x1:new_x2] \u001b[38;5;241m=\u001b[39m object_resized\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Update bounding box to normalized format\u001b[39;00m\n\u001b[0;32m     49\u001b[0m new_cx \u001b[38;5;241m=\u001b[39m (new_x1 \u001b[38;5;241m+\u001b[39m new_x2) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m w\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (1068,134,3) into shape (893,134,3)"
     ]
    }
   ],
   "source": [
    "## Augmentation \n",
    "# Scale a dataset to 1.5. scale factor \n",
    "# Have a dataset of red and yellow flags. Have other datasets of red flags where the red flag is larger and more zoomed in\n",
    "# This is to scale the flags and update the annotations \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def scale_object(image, bbox, scale_factor):\n",
    "    \"\"\"\n",
    "    Scales the object within a bounding box by a given scale factor.\n",
    "    Args:\n",
    "        image (numpy array): Input image.\n",
    "        bbox (tuple): Bounding box in the format (class_id, center_x, center_y, width, height) in normalized format.\n",
    "        scale_factor (float): Factor by which to scale the object.\n",
    "    Returns:\n",
    "        numpy array: Image with the object scaled.\n",
    "        tuple: Updated bounding box.\n",
    "    \"\"\"\n",
    "    h, w, _ = image.shape\n",
    "    class_id, cx, cy, bw, bh = bbox\n",
    "    cx, cy, bw, bh = cx * w, cy * h, bw * w, bh * h\n",
    "\n",
    "    # Calculate new bounding box dimensions\n",
    "    new_bw = bw * scale_factor\n",
    "    new_bh = bh * scale_factor\n",
    "\n",
    "    # Crop and resize the object\n",
    "    x1, y1 = int(cx - bw / 2), int(cy - bh / 2)\n",
    "    x2, y2 = int(cx + bw / 2), int(cy + bh / 2)\n",
    "    object_crop = image[y1:y2, x1:x2]\n",
    "    object_resized = cv2.resize(object_crop, (int(new_bw), int(new_bh)))\n",
    "\n",
    "    # Replace the object in the image\n",
    "    new_x1, new_y1 = int(cx - new_bw / 2), int(cy - new_bh / 2)\n",
    "    new_x2, new_y2 = new_x1 + object_resized.shape[1], new_y1 + object_resized.shape[0]\n",
    "\n",
    "    # Ensure boundaries are within the image dimensions\n",
    "    new_x1 = max(0, new_x1)\n",
    "    new_y1 = max(0, new_y1)\n",
    "    new_x2 = min(w, new_x2)\n",
    "    new_y2 = min(h, new_y2)\n",
    "\n",
    "    # Paste the resized object back into the image\n",
    "    image[new_y1:new_y2, new_x1:new_x2] = object_resized\n",
    "\n",
    "    # Update bounding box to normalized format\n",
    "    new_cx = (new_x1 + new_x2) / 2 / w\n",
    "    new_cy = (new_y1 + new_y2) / 2 / h\n",
    "    new_bw = (new_x2 - new_x1) / w\n",
    "    new_bh = (new_y2 - new_y1) / h\n",
    "\n",
    "    return image, (class_id, new_cx, new_cy, new_bw, new_bh)\n",
    "\n",
    "def process_folder(images_folder, annotations_folder, output_folder, scale_factor=1.5):\n",
    "    \"\"\"\n",
    "    Processes a folder of images and annotations, scaling objects in images and updating annotations.\n",
    "    Args:\n",
    "        images_folder (str): Path to the folder containing images.\n",
    "        annotations_folder (str): Path to the folder containing YOLO annotations.\n",
    "        output_folder (str): Path to the output folder.\n",
    "        scale_factor (float): Factor by which to scale objects.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_folder, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_folder, \"annotations\"), exist_ok=True)\n",
    "\n",
    "    for image_file in os.listdir(images_folder):\n",
    "        if not image_file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "            continue\n",
    "        \n",
    "        base_name = os.path.splitext(image_file)[0]\n",
    "        annotation_file = os.path.join(annotations_folder, f\"{base_name}.txt\")\n",
    "        if not os.path.exists(annotation_file):\n",
    "            continue\n",
    "\n",
    "        # Load image and annotation\n",
    "        image_path = os.path.join(images_folder, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "        h, w, _ = image.shape\n",
    "\n",
    "        with open(annotation_file, \"r\") as f:\n",
    "            annotations = [list(map(float, line.strip().split())) for line in f.readlines()]\n",
    "\n",
    "        new_annotations = []\n",
    "        for bbox in annotations:\n",
    "            image, new_bbox = scale_object(image, bbox, scale_factor)\n",
    "            new_annotations.append(new_bbox)\n",
    "\n",
    "        # Save the updated image and annotation\n",
    "        output_image_path = os.path.join(output_folder, \"images\", image_file)\n",
    "        output_annotation_path = os.path.join(output_folder, \"annotations\", f\"{base_name}.txt\")\n",
    "\n",
    "        cv2.imwrite(output_image_path, image)\n",
    "\n",
    "        with open(output_annotation_path, \"w\") as f:\n",
    "            for ann in new_annotations:\n",
    "                f.write(\" \".join(f\"{x:.6f}\" for x in ann) + \"\\n\")\n",
    "\n",
    "images_folder = \"D:\\FlagDetectionDatasets\\ExportedTaskDatasetsZips\\test\\testimages\"\n",
    "annotations_folder = \"D:\\FlagDetectionDatasets\\ExportedTaskDatasetsZips\\test\\testannotatioms\"\n",
    "output_folder = \"D:\\FlagDetectionDatasets\\ExportedTaskDatasetsZips\\Job_73\\Job_73_scaled\"\n",
    "scale_factor = 1.5\n",
    "\n",
    "process_folder(images_folder, annotations_folder, output_folder, scale_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482fa228-9ab4-4522-8079-fc2d9acb08ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
