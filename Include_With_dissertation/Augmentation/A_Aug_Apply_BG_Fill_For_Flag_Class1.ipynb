{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad7ebb11-cb71-4b25-b6cd-1a680c0c0d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_Aug_Apply_BG_Fill_For_Flag_Class\n",
    "'''\n",
    "Include in dissertation\n",
    "This script refines datasets containing Green Coast flags by removing incorrectly hanging red/yellow flags. \n",
    "Bounding boxes for a specified class (`class_to_fill`) are filled with sampled background colors, \n",
    "while protecting regions corresponding to another specified class (`class_to_keep`). The resulting images \n",
    "and updated YOLO-format annotation files are saved to the target directory.\n",
    "\n",
    "## Workflow:\n",
    "1. Identify Bounding Boxes:\n",
    "   - Reads YOLO-format annotations to locate the bounding boxes for the `class_to_fill` and `class_to_keep`.\n",
    "2. Background Sampling and Filling:\n",
    "   - Samples surrounding areas (above, left, right) to calculate a fill color for the `class_to_fill` regions.\n",
    "   - Excludes overlapping regions for `class_to_keep` during filling.\n",
    "3. Save Results\n",
    "   - Saves the modified images with filled regions.\n",
    "   - Updates and saves the corresponding YOLO-format annotation files.\n",
    "\n",
    "## Parameters:\n",
    "- `src_folder` (str): Path to the folder containing source images and annotations.\n",
    "- `tgt_folder` (str): Path to save the modified images and annotations.\n",
    "- `class_to_fill` (int): The class ID of the bounding boxes to be removed and filled.\n",
    "- `class_to_keep` (int): The class ID of the bounding boxes to be protected from filling.\n",
    "- `padding` (tuple): Padding for bounding box adjustments (top, right, bottom, left).\n",
    "- `x_offset` (int): Horizontal offset applied to the `class_to_fill` regions.\n",
    "\n",
    "## Functions:\n",
    "- `create_filled_filename`: Generates a new filename for processed images and annotations.\n",
    "- `fill_bbox_with_background`: Fills bounding boxes for `class_to_fill` with sampled background color.\n",
    "- `fill_class`: Processes all images and annotations in a source folder.\n",
    "\n",
    "## Example:\n",
    "1. Specify the paths to the source and target folders:\n",
    "    - `src_folder = 'path/to/source/images'`\n",
    "    - `tgt_folder = 'path/to/target/output'`\n",
    "2. Define the classes to fill and protect:\n",
    "    - `class_to_fill = 1` (e.g., red/yellow flags)\n",
    "    - `class_to_keep = 3` (e.g., Green Coast flags)\n",
    "3. Run the script to process all images and annotations:\n",
    "    fill_class(src_folder, tgt_folder, class_to_fill, class_to_keep, padding=(5, 5, 0, 5), x_offset=30)\n",
    "\n",
    "## Notes:\n",
    "- Input images must be in `.png` format with corresponding `.txt` YOLO annotation files.\n",
    "- Processed images will be saved with modified filenames indicating the filled class.\n",
    "'''\n",
    "    \n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_filled_filename(file_name, source_class_id):\n",
    "    \"\"\"\n",
    "    Create a new filename for the merged image or annotation based on user specifications.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): The original filename.\n",
    "        source_class_id (int): The class ID to be removed and filled in the images.\n",
    "\n",
    "    Returns:\n",
    "        str: A new filename that follows the specified naming convention.\n",
    "    \"\"\"\n",
    "    base_name, ext = os.path.splitext(file_name)\n",
    "    new_name = f\"{base_name}_Fill_CLS_{source_class_id}{ext}\"\n",
    "    #new_name = file_name\n",
    "\n",
    "    return new_name\n",
    "\n",
    "def fill_bbox_with_background(tgt_image, tgt_annotations, target_class, keep_class_id, x_offset=0, padding=(10, 10, 10, 10)):\n",
    "    \"\"\"\n",
    "    Fill the bounding box for the target class with the background colour sampled from surrounding areas,\n",
    "    excluding areas that overlap with the keep class bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        tgt_image (ndarray): The target image.\n",
    "        tgt_annotations (list): List of annotations (YOLO format).\n",
    "        target_class (int): The class ID of the target bounding box to be filled.\n",
    "        keep_class_id (int): The class ID of the bounding box to be excluded from the filling area.\n",
    "        padding (tuple): Padding for (top, right, bottom, left) directions.\n",
    "        x_offset (int): Horizontal offset applied to the bounding box.\n",
    "\n",
    "    Returns:\n",
    "        tgt_image (ndarray): The updated image with the target bounding box filled.\n",
    "    \"\"\"\n",
    "    top_pad, right_pad, bottom_pad, left_pad = padding\n",
    "    image_height, image_width = tgt_image.shape[:2]\n",
    "    target_bbox = None\n",
    "\n",
    "    # Create an exclusion mask for the keep class\n",
    "    exclusion_mask = np.zeros((image_height, image_width), dtype=np.uint8)\n",
    "    for annotation in tgt_annotations:\n",
    "        class_id, x_center, y_center, width, height = annotation\n",
    "        if int(class_id) == keep_class_id:\n",
    "            x_min = int((x_center - width / 2) * image_width)\n",
    "            y_min = int((y_center - height / 2) * image_height)\n",
    "            x_max = int((x_center + width / 2) * image_width)\n",
    "            y_max = int((y_center + height / 2) * image_height)\n",
    "            cv2.rectangle(exclusion_mask, (x_min, y_min), (x_max, y_max), 255, thickness=-1)\n",
    "\n",
    "    for annotation in tgt_annotations:\n",
    "        class_id, x_center, y_center, width, height = annotation\n",
    "        if int(class_id) == target_class:\n",
    "            # Apply x_offset to background fill\n",
    "            x_min = int((x_center - width / 2) * image_width) + x_offset\n",
    "            y_min = int((y_center - height / 2) * image_height)\n",
    "            x_max = int((x_center + width / 2) * image_width) + x_offset\n",
    "            y_max = int((y_center + height / 2) * image_height)\n",
    "\n",
    "            # Ensure coordinates are within bounds\n",
    "            x_min = max(0, x_min - left_pad)\n",
    "            y_min = max(0, y_min - top_pad)\n",
    "            x_max = min(image_width, x_max + right_pad)\n",
    "            y_max = min(image_height, y_max + bottom_pad)\n",
    "\n",
    "            # Exclude overlapping areas with keep class\n",
    "            target_mask = np.zeros((image_height, image_width), dtype=np.uint8)\n",
    "            cv2.rectangle(target_mask, (x_min, y_min), (x_max, y_max), 255, thickness=-1)\n",
    "            target_mask = cv2.bitwise_and(target_mask, cv2.bitwise_not(exclusion_mask))\n",
    "\n",
    "            # Sample regions outside the bounding box\n",
    "            top = tgt_image[max(0, y_min - top_pad):y_min, x_min:x_max]\n",
    "            left = tgt_image[y_min:y_max, max(0, x_min - left_pad):x_min]\n",
    "            right = tgt_image[y_min:y_max, x_max:min(image_width, x_max + right_pad)]\n",
    "\n",
    "            # Combine the mean colours from sampled regions\n",
    "            sampled_colors = []\n",
    "            if top.size > 0:\n",
    "                sampled_colors.append(top.mean(axis=(0, 1)))\n",
    "            if left.size > 0:\n",
    "                sampled_colors.append(left.mean(axis=(0, 1)))\n",
    "            if right.size > 0:\n",
    "                sampled_colors.append(right.mean(axis=(0, 1)))\n",
    "\n",
    "            if not sampled_colors:\n",
    "                print(\"Sampling failed for bounding box. Skipping background filling.\")\n",
    "                continue\n",
    "\n",
    "            # Calculate the average colour from all sampled regions\n",
    "            background_color = np.mean(sampled_colors, axis=0).astype(np.uint8)\n",
    "\n",
    "            # Fill the target mask area with the computed background colour\n",
    "            tgt_image[target_mask > 0] = background_color\n",
    "            target_bbox = (x_min, y_min, x_max, y_max)\n",
    "            break\n",
    "\n",
    "    if target_bbox is None:\n",
    "        return\n",
    "    return tgt_image\n",
    "\n",
    "def fill_bbox_with_backgroundWORKING(tgt_image, tgt_annotations, target_class, keep_class_id, x_offset=0, padding=(10, 10, 10, 10)):\n",
    "    \"\"\"\n",
    "    Fill the bounding box for the target class with the background colour sampled from surrounding areas,\n",
    "    excluding areas that overlap with the keep class bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        tgt_image (ndarray): The target image.\n",
    "        tgt_annotations (list): List of annotations (YOLO format).\n",
    "        target_class (int): The class ID of the target bounding box to be filled.\n",
    "        keep_class_id (int): The class ID of the bounding box to be excluded from the filling area.\n",
    "        padding (tuple): Padding for (top, right, bottom, left) directions.\n",
    "        x_offset (int): Horizontal offset applied to the bounding box.\n",
    "\n",
    "    Returns:\n",
    "        tgt_image (ndarray): The updated image with the target bounding box filled.\n",
    "    \"\"\"\n",
    "    top_pad, right_pad, bottom_pad, left_pad = padding\n",
    "    image_height, image_width = tgt_image.shape[:2]\n",
    "    target_bbox = None\n",
    "\n",
    "    # Create an exclusion mask for the keep class\n",
    "    exclusion_mask = np.zeros((image_height, image_width), dtype=np.uint8)\n",
    "    for annotation in tgt_annotations:\n",
    "        class_id, x_center, y_center, width, height = annotation\n",
    "        if int(class_id) == keep_class_id:\n",
    "            x_min = int((x_center - width / 2) * image_width)\n",
    "            y_min = int((y_center - height / 2) * image_height)\n",
    "            x_max = int((x_center + width / 2) * image_width)\n",
    "            y_max = int((y_center + height / 2) * image_height)\n",
    "            cv2.rectangle(exclusion_mask, (x_min, y_min), (x_max, y_max), 255, thickness=-1)\n",
    "\n",
    "    for annotation in tgt_annotations:\n",
    "        class_id, x_center, y_center, width, height = annotation\n",
    "        if int(class_id) == target_class:\n",
    "            # Apply x_offset to background fill\n",
    "            x_min = int((x_center - width / 2) * image_width) + x_offset\n",
    "            y_min = int((y_center - height / 2) * image_height)\n",
    "            x_max = int((x_center + width / 2) * image_width) + x_offset\n",
    "            y_max = int((y_center + height / 2) * image_height)\n",
    "\n",
    "            # Ensure coordinates are within bounds\n",
    "            x_min = max(0, x_min - left_pad)\n",
    "            y_min = max(0, y_min - top_pad)\n",
    "            x_max = min(image_width, x_max + right_pad)\n",
    "            y_max = min(image_height, y_max + bottom_pad)\n",
    "\n",
    "            # Exclude overlapping areas with keep class\n",
    "            target_mask = np.zeros((image_height, image_width), dtype=np.uint8)\n",
    "            cv2.rectangle(target_mask, (x_min, y_min), (x_max, y_max), 255, thickness=-1)\n",
    "            target_mask = cv2.bitwise_and(target_mask, cv2.bitwise_not(exclusion_mask))\n",
    "\n",
    "            # Sample regions outside the bounding box\n",
    "            top = tgt_image[max(0, y_min - top_pad):y_min, x_min:x_max]\n",
    "            left = tgt_image[y_min:y_max, max(0, x_min - left_pad):x_min]\n",
    "            right = tgt_image[y_min:y_max, x_max:min(image_width, x_max + right_pad)]\n",
    "\n",
    "            # Combine the mean colours from sampled regions\n",
    "            sampled_colors = []\n",
    "            if top.size > 0:\n",
    "                sampled_colors.append(top.mean(axis=(0, 1)))\n",
    "            if left.size > 0:\n",
    "                sampled_colors.append(left.mean(axis=(0, 1)))\n",
    "            if right.size > 0:\n",
    "                sampled_colors.append(right.mean(axis=(0, 1)))\n",
    "\n",
    "            if not sampled_colors:\n",
    "                print(\"Sampling failed for bounding box. Skipping background filling.\")\n",
    "                continue\n",
    "\n",
    "            # Calculate the average colour from all sampled regions\n",
    "            background_color = np.mean(sampled_colors, axis=0).astype(np.uint8)\n",
    "\n",
    "            # Fill the target mask area with the computed background colour\n",
    "            tgt_image[target_mask > 0] = background_color\n",
    "            target_bbox = (x_min, y_min, x_max, y_max)\n",
    "            break\n",
    "\n",
    "    if target_bbox is None:\n",
    "        return\n",
    "    return tgt_image\n",
    "\n",
    "\n",
    "def fill_class(src_folder, tgt_folder, source_class_id, keep_class_id, scale_factor=1.0, padding=(10, 10, 10, 10), x_offset=0):\n",
    "    if not os.path.exists(tgt_folder):\n",
    "        os.makedirs(tgt_folder)\n",
    "    for file_name in os.listdir(src_folder):\n",
    "        if file_name.lower().endswith('.png'):\n",
    "            src_image = cv2.imread(os.path.join(src_folder, file_name))\n",
    "            src_annotation_path = os.path.join(src_folder, os.path.splitext(file_name)[0] + \".txt\")\n",
    "            if not os.path.exists(src_annotation_path):\n",
    "                print(f\"No annotations for {file_name} in source ({src_folder}). Skipping.\")\n",
    "                continue\n",
    "            with open(src_annotation_path, 'r') as f:\n",
    "                src_annotations = [list(map(float, line.split())) for line in f]\n",
    "\n",
    "            # Fill the class with the background colour samples, excluding keep_class_id\n",
    "            background_filled_image = fill_bbox_with_background(\n",
    "                tgt_image=src_image,\n",
    "                tgt_annotations=src_annotations,\n",
    "                target_class=source_class_id,\n",
    "                keep_class_id=keep_class_id,\n",
    "                x_offset=x_offset,\n",
    "                padding=padding\n",
    "            )\n",
    "\n",
    "            # Remove the annotations of the target class\n",
    "            updated_annotations = [\n",
    "                annotation for annotation in src_annotations\n",
    "                if int(annotation[0]) != source_class_id\n",
    "            ]\n",
    "\n",
    "            # Save the image and annotation file\n",
    "            if background_filled_image is not None:\n",
    "                new_filename = create_filled_filename(file_name, source_class_id)\n",
    "                output_path = os.path.join(tgt_folder, new_filename)\n",
    "                cv2.imwrite(output_path, background_filled_image)\n",
    "\n",
    "                # Save the updated annotations\n",
    "                new_annotation_path = os.path.join(\n",
    "                    tgt_folder, os.path.splitext(new_filename)[0] + \".txt\"\n",
    "                )\n",
    "                with open(new_annotation_path, 'w') as f:\n",
    "                    for annotation in updated_annotations:\n",
    "                        annotation[0] = int(annotation[0])  # Ensure class ID is an integer\n",
    "                        f.write(' '.join(f\"{value:.6f}\" if i > 0 else str(int(value)) for i, value in enumerate(annotation)) + '\\n')\n",
    "\n",
    "                \n",
    "# Stage 1 - fill the red / yellow class bounding box \n",
    "#fill_class_in = 'D:/FlagDetectionDatasets/ExportedDatasetsReduced/Job_52_illum'\n",
    "#output = 'D:/FlagDetectionDatasets/ExportedDatasetsReduced/Job_52_ClassFill'\n",
    "#fill_class_in = 'D:/FlagDetectionDatasets/ExportedDatasetsReduced/Job_51_illum'\n",
    "#output = 'D:/FlagDetectionDatasets/ExportedDatasetsReduced/Job_51_ClassFill'\n",
    "\n",
    "fill_class_in = 'D:/FlagDetectionDatasets/Augmentation/Switch_class_in_images_sets/Merge_red_yellow_mask_from_class_1_in_30_to_24/000328' #Flag_To_Swap_From_30_Class_1'\n",
    "output = 'D:/FlagDetectionDatasets/Augmentation/Switch_class_in_images_sets/Merge_red_yellow_mask_from_class_1_in_30_to_24/000328_Filled2' #Flag_To_Swap_From_30_Class_2_filled'\n",
    "\n",
    "class_to_fill = 2 # Fill blue flag 1  # Fill red / yellow flag class \n",
    "class_to_keep = 1 # red yellow 3  # Green coast flag to protect \n",
    "x_offset = 0   # 30 works well for set 51 - pointing to the right \n",
    "padding=(5, 5, 0, 10) #(5, 5, 0, 5)   # Padding: (top, right, bottom, left) #padding=(0, 5, 5, 5)\n",
    "\n",
    "fill_class(fill_class_in, output, class_to_fill, class_to_keep, padding, x_offset=x_offset)\n",
    "\n",
    "# Next run # Title: A_Aug_Replace_Class_Using_HSV_Red_Yellow_colour_threshold.jpynb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b41a8af-d14e-442f-9a2e-d8423006806a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
