{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18e3fde7-6482-4bf5-9fb6-4c0110d931e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Title: A_Aug_Replace_Class_Using_HSV_Red_Yellow_colour_threshold.jpynb \n",
    "# Include with dissertation\n",
    "\n",
    "## Purpose:\n",
    "Stage in processing pipeline to make Green Coast flag sets usable.  \n",
    "Refines Green Coast flag datasets by cleaning up remnants of dark red/yellow left after bounding box filling.  \n",
    "Uses HSV thresholds to identify and fill flagged regions with colors sampled from surrounding areas, while visualizing sampling regions.\n",
    "\n",
    "## Workflow:\n",
    "1. Uses HSV thresholds to identify red and yellow regions in the image.\n",
    "2. Restricts mask refinement to areas above or adjacent to bounding boxes for the target class.\n",
    "3. Samples colors from surrounding regions (left, right, or up) to fill flagged areas.\n",
    "4. Saves the cleaned images and copies the corresponding YOLO annotation files.\n",
    "\n",
    "## Parameters:\n",
    "- `src_folder` (str): Path to the folder containing source images.\n",
    "- `tgt_folder` (str): Path to save processed images and annotations.\n",
    "- `annotations_src_folder` (str): Path to the folder containing YOLO annotations.\n",
    "- `target_class_id` (int): The class ID of the bounding boxes to refine.\n",
    "\n",
    "## Dependencies:\n",
    "- Python 3.x\n",
    "- OpenCV\n",
    "- NumPy\n",
    "- Matplotlib\n",
    "\n",
    "## Notes:\n",
    "- Input images should be in `.png` format with YOLO `.txt` annotation files.\n",
    "- Sampling is configured for left, right, or up regions. Uncomment appropriate sections as needed.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Set a different font to avoid issues with DejaVuSans\n",
    "rcParams.update({'font.family': 'sans-serif', 'font.sans-serif': ['Arial']})\n",
    "\n",
    "def fill_flag_mask(img_path, annotations, target_class_id, output_mask_path=None):\n",
    "    \"\"\"\n",
    "    Processes an image to refine red and yellow flag areas within a new search area based on HSV thresholds\n",
    "    and fills all detected regions with sampled background colors. It visualizes sampling regions with bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        img_path (str): Path to the input image.\n",
    "        annotations (list): List of YOLO-format annotations for the image.\n",
    "        target_class_id (int): The class ID for which the mask should be refined within the adjusted search area.\n",
    "        output_mask_path (str): Path to save the processed image with filled areas.\n",
    "\n",
    "    Returns:\n",
    "        img_filled (numpy.ndarray): The processed image.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image not found or unable to read: {img_path}\")\n",
    "    \n",
    "    original_img = img.copy()  # Keep a copy for visualization\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define thresholds for red and yellow in HSV\n",
    "    lower_red1, upper_red1 = np.array([0, 70, 50]), np.array([10, 255, 255])\n",
    "    lower_red2, upper_red2 = np.array([160, 70, 50]), np.array([180, 255, 255])\n",
    "    lower_yellow, upper_yellow = np.array([15, 70, 70]), np.array([40, 255, 255])\n",
    "\n",
    "    # Generate masks for red and yellow\n",
    "    mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "    # Combine the masks\n",
    "    mask_red = cv2.bitwise_or(mask_red1, mask_red2)\n",
    "    combined_mask = cv2.bitwise_or(mask_red, mask_yellow)\n",
    "\n",
    "    # Refine the mask\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    filled_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    smoothed_mask = cv2.GaussianBlur(filled_mask, (5, 5), sigmaX=1)\n",
    "\n",
    "    # Locate the bounding box for the target class\n",
    "    image_height, image_width = img.shape[:2]\n",
    "    target_boxes = [\n",
    "        annotation for annotation in annotations\n",
    "        if int(annotation[0]) == target_class_id\n",
    "    ]\n",
    "\n",
    "    if not target_boxes:\n",
    "        raise ValueError(f\"No bounding box found for target class ID {target_class_id}.\")\n",
    "\n",
    "    # Process each target bounding box\n",
    "    for box in target_boxes:\n",
    "        class_id, x_center, y_center, width, height = box\n",
    "        x_min = int((x_center - width / 2) * image_width)\n",
    "        y_min = int((y_center - height / 2) * image_height)\n",
    "        x_max = int((x_center + width / 2) * image_width)\n",
    "        y_max = int((y_center + height / 2) * image_height)\n",
    "\n",
    "        # Calculate the adjusted search area\n",
    "        search_height = int(height * image_height)\n",
    "        search_width = int(width * image_width)\n",
    "\n",
    "        search_x_min = x_min\n",
    "        search_x_max = x_max\n",
    "        search_y_max = y_min + (y_max - y_min) // 2\n",
    "        search_y_min = max(0, search_y_max - search_height)\n",
    "\n",
    "        # Restrict the mask to the new search area\n",
    "        restricted_mask = np.zeros_like(smoothed_mask)\n",
    "        restricted_mask[search_y_min:search_y_max, search_x_min:search_x_max] = smoothed_mask[search_y_min:search_y_max, search_x_min:search_x_max]\n",
    "\n",
    "        # Find contours in the restricted mask\n",
    "        contours, _ = cv2.findContours(restricted_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if not contours:\n",
    "            continue\n",
    "\n",
    "        # Iterate through all detected contours\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            # Adjust sampling to only go left and up or right and up\n",
    "            surrounding_regions = [\n",
    "                #(max(0, y-10), y, max(0, x-10), x),  # Left\n",
    "                #(max(0, y-10), y, x+w, min(image_width, x+w+10)),  # Right\n",
    "                # Uncomment the next line for \"Up\" sampling (add this alongside Left or Right as needed)\n",
    "                (max(0, y-10), y, x, x+w)  # Up\n",
    "            ]\n",
    "\n",
    "            sampled_colors = []\n",
    "            for (r_y_min, r_y_max, r_x_min, r_x_max) in surrounding_regions:\n",
    "                region = img[r_y_min:r_y_max, r_x_min:r_x_max]\n",
    "                if region.size > 0 and np.any(region):\n",
    "                    sampled_colors.append(region.mean(axis=(0, 1)))\n",
    "\n",
    "                    # Draw bounding box around sampling regions for visualization\n",
    "                    cv2.rectangle(original_img, (r_x_min, r_y_min), (r_x_max, r_y_max), (0, 255, 0), 2)\n",
    "\n",
    "            if not sampled_colors:\n",
    "                print(f\"Sampling failed for bounding box: x={x}, y={y}, w={w}, h={h}\")\n",
    "                continue\n",
    "\n",
    "            # Calculate the average color and fill the region\n",
    "            fill_color = np.mean(sampled_colors, axis=0).astype(np.uint8)\n",
    "            img[y:y+h, x:x+w][restricted_mask[y:y+h, x:x+w] > 0] = fill_color\n",
    "\n",
    "    # Visualize the result\n",
    "    #plt.figure(figsize=(15, 15))\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    #plt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
    "    #plt.title(\"Original Image with Sampling Regions\")\n",
    "\n",
    "    #plt.subplot(1, 2, 2)\n",
    "    #plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    #plt.title(\"Processed Image with Filled Areas\")\n",
    "    #plt.show()\n",
    "\n",
    "    # Save the result if output path is provided\n",
    "    if output_mask_path:\n",
    "        cv2.imwrite(output_mask_path, img)\n",
    "    return img\n",
    "    \n",
    "def fill_class_by_colour(src_folder, tgt_folder, annotations_src_folder, target_class_id):\n",
    "    \"\"\"\n",
    "    Processes all images in a folder to refine and fill flag areas based on HSV thresholds within the adjusted search area.\n",
    "\n",
    "    Args:\n",
    "        src_folder (str): Path to the folder containing source images.\n",
    "        tgt_folder (str): Path to the folder to save processed images.\n",
    "        annotations_src_folder (str): Path to the folder containing YOLO annotations.\n",
    "        target_class_id (int): The class ID for which the mask should be refined within the adjusted search area.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(tgt_folder):\n",
    "        os.makedirs(tgt_folder)\n",
    "\n",
    "    for file_name in os.listdir(src_folder):\n",
    "        if file_name.lower().endswith('.png'):\n",
    "            src_image_path = os.path.normpath(os.path.join(src_folder, file_name))\n",
    "            annotation_path = os.path.normpath(os.path.join(annotations_src_folder, os.path.splitext(file_name)[0] + \".txt\"))\n",
    "            \n",
    "            if not os.path.exists(annotation_path):\n",
    "                print(f\"No annotation file for {file_name} in {src_folder}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            with open(annotation_path, 'r') as f:\n",
    "                annotations = [list(map(float, line.split())) for line in f]\n",
    "\n",
    "            intermediate_mask_path = os.path.normpath(os.path.join(tgt_folder, f\"{file_name}\"))\n",
    "            fill_flag_mask(src_image_path, annotations, target_class_id, intermediate_mask_path)\n",
    "\n",
    "            # Copy the annotation file to the target folder\n",
    "            target_annotation_path = os.path.normpath(os.path.join(tgt_folder, os.path.basename(annotation_path)))\n",
    "            shutil.copy(annotation_path, target_annotation_path)\n",
    "            # print(f\"Copied annotation to {target_annotation_path}\")\n",
    "\n",
    "# Run to fill target area with bg colour \n",
    "src_folder = 'D:/FlagDetectionDatasets/ExportedDatasetsReduced/Job_51_ClassFill'\n",
    "tgt_folder = 'D:/FlagDetectionDatasets/ExportedDatasetsReduced/Job_51_HSVFill'\n",
    "annotations_src_folder = 'D:/FlagDetectionDatasets/ExportedDatasetsReduced/Job_51_ClassFill'\n",
    "target_class_id = 3  # Class ID to target = 3 Green Cost flag \n",
    "\n",
    "fill_class_by_colour(src_folder, tgt_folder, annotations_src_folder, target_class_id)\n",
    "# Run Stage 1 first - Stage 1: A_Aug_Apply_BG_Fill_For_Flag_Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2b9bc8-0740-424f-a4f6-aaed2bf04af0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
