{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc8eef-389d-408c-8d25-dcf92303d9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to process Job_42...scale factor is: 1.4\n",
      "Processing completed for job: Job_42\n",
      "Beginning to process Job_48...scale factor is: 1.5\n",
      "Processing completed for job: Job_48\n",
      "Beginning to process Job_50...scale factor is: 1.4\n",
      "Processing completed for job: Job_50\n",
      "Beginning to process Job_72...scale factor is: 1.4\n",
      "Processing completed for job: Job_72\n",
      "Beginning to process Job_76...scale factor is: 1.7\n",
      "Processing completed for job: Job_76\n",
      "Beginning to process Job_87...scale factor is: 3.0\n",
      "Processing completed for job: Job_87\n",
      "Beginning to process Job_104...scale factor is: 3.0\n",
      "Processing completed for job: Job_104\n",
      "Beginning to process Job_105...scale factor is: 2.6\n",
      "Processing completed for job: Job_105\n",
      "Beginning to process Job_106...scale factor is: 2.7\n",
      "Processing completed for job: Job_106\n",
      "Beginning to process Job_114...scale factor is: 2.5\n",
      "Processing completed for job: Job_114\n",
      "Beginning to process Job_115...scale factor is: 2.2\n",
      "Processing completed for job: Job_115\n",
      "Beginning to process Job_116...scale factor is: 2.2\n",
      "Processing completed for job: Job_116\n",
      "Beginning to process Job_117...scale factor is: 2.0\n",
      "Processing completed for job: Job_117\n",
      "Beginning to process Job_119...scale factor is: 1.7\n"
     ]
    }
   ],
   "source": [
    "# A_AugmentationScaleAndUpdateAnnotationsANdPreview\n",
    "# Scale images and update annotations \n",
    "# Scale the entire image and overlay it onto the original image size. \n",
    "#  Update the annotations based on the scaled coordinates of the bounding boxes. \n",
    "# Scaling the Image:\n",
    "# Scaled image by a specified factor using cv2.resize.\n",
    "# Overlay the scaled image onto the original-sized canvas.\n",
    "# Adjust and scale annotations using the same factor.\n",
    "# Clip Bounding box dimensions to the original image dimensions????\n",
    "\n",
    "# Shifted the overlaid image upwards (offset_y) so it lowerpart fits within the original dimensions.\n",
    "# Adjust bounding box cy values by subtracting the vertical offset.\n",
    "# Bounding Box Format Handling:\n",
    "# YOLO annotations define bounding boxes relative to the image dimensions. \n",
    "# When scaling, boxes remain inside the image, with adjusted dimensions, and width and height are scaled consistently.\n",
    "# Offset Calculation:\n",
    "# Offsets are calculated correctly if the scaled image is smaller than the original. \n",
    "# The offset_x and offset_y values should consider both positive and negative adjustments.\n",
    "\n",
    "# Handling of Bounding Boxes:\n",
    "# Calculated absolute bounding box coordinates (x_min, y_min, x_max, y_max) to ensure valid and clipped bounding boxes.\n",
    "# Check invalid boxes and skip them\n",
    "# Offset logic handles both positive and negative values \n",
    "# new_annotations.append skips invalid boxes.\n",
    "# YOLO annotations are formatted with six decimal places.\n",
    "\n",
    "# Log a confirmation mesage for each processed image\n",
    "# Print a mssg if an annotation is missing and skip the image\n",
    "\n",
    "# Handles a folder of images and corresponding annotations.\n",
    "# Save scaled images and updated annotation to the output folder.\n",
    "\n",
    "# Further info: Calcualte horizontal (offset_x) and vertical (offset_y) offsets to center the scaled image within the original dimensions.\n",
    "# Clip scaled areas beyond the original image dimensions \n",
    "# Adjust annotations to reflect the scaled image's new positions and dimensions.\n",
    "\n",
    "# new_annotations.append(f\"{class_id} {cx} {cy} {bw} {bh}\\n\")\n",
    "# Update the annotation with six decimal places\n",
    "# new_annotations.append(f\"{class_id:.6f} {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}\\n\")\n",
    "\n",
    "# output_images_folder = os.path.join(output_folder, \"images\")\n",
    "#output_annotations_folder = os.path.join(output_folder, \"annotations\")\n",
    "    \n",
    "#   output_images_folder = output_folder\n",
    "#   output_annotations_folder = output_folder\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt  # For preview\n",
    "import numpy as np\n",
    "\n",
    "def load_class_names(obj_names_path):\n",
    "    \"\"\"\n",
    "    Loads class names from the obj.names file.\n",
    "    Args:\n",
    "        obj_names_path (str): Path to the obj.names file.\n",
    "    Returns:\n",
    "        list: A list of class names.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(obj_names_path):\n",
    "        raise FileNotFoundError(f\"obj.names file not found at {obj_names_path}\")\n",
    "    with open(obj_names_path, \"r\") as f:\n",
    "        class_names = f.read().strip().split(\"\\n\")\n",
    "    return class_names\n",
    "\n",
    "\n",
    "def generate_output_path(base_path, file_name, suffix, extension=None):\n",
    "        base_name = os.path.splitext(file_name)[0]\n",
    "        ext = extension or os.path.splitext(file_name)[1]\n",
    "        return os.path.join(base_path, f\"{base_name}_{suffix}{ext}\")\n",
    "\n",
    "\n",
    "def generate_scale_string(scale_factor):\n",
    "    \"\"\"\n",
    "    Converts the scale factor into a string with a pattern 'scale_x_y' \n",
    "    where the decimal point is replaced with an underscore.\n",
    "\n",
    "    Args:\n",
    "        scale_factor (float): The scale factor.\n",
    "\n",
    "    Returns:\n",
    "        str: The scale factor string in the format 'scale_x_y'.\n",
    "    \"\"\"\n",
    "    return f\"scale_{str(scale_factor).replace('.', '_')}\"\n",
    "\n",
    "\n",
    "def center_image_and_update_annotations(image_path, annotation_path, output_image_path, output_annotation_path):\n",
    "    \"\"\"\n",
    "    Centers the image based on bounding boxes of classes 0, 1, 2, and 3,\n",
    "    and updates all annotations with the computed shift.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        annotation_path (str): Path to the corresponding annotation file.\n",
    "        output_image_path (str): Path to save the centered image.\n",
    "        output_annotation_path (str): Path to save the updated annotations.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    original_h, original_w = image.shape[:2]\n",
    "\n",
    "    # Initialize variables for bounding box calculation\n",
    "    x_min, y_min, x_max, y_max = 1.0, 1.0, 0.0, 0.0  # Normalized bounds\n",
    "    valid_bounding_boxes = False\n",
    "\n",
    "    # Read annotations and calculate center of relevant bounding boxes (classes 0, 1, 2, 3)\n",
    "    with open(annotation_path, \"r\") as annotation_file:\n",
    "        for annotation in annotation_file:\n",
    "            class_id, cx, cy, bw, bh = map(float, annotation.split())\n",
    "            if int(class_id) > 3:  # Only consider flag classes 0, 1, 2, 3 for centering\n",
    "                continue\n",
    "\n",
    "            valid_bounding_boxes = True\n",
    "            x_min = min(x_min, cx - bw / 2)\n",
    "            y_min = min(y_min, cy - bh / 2)\n",
    "            x_max = max(x_max, cx + bw / 2)\n",
    "            y_max = max(y_max, cy + bh / 2)\n",
    "\n",
    "    # Skip centering if no relevant bounding boxes are found\n",
    "    if not valid_bounding_boxes:\n",
    "        print(f\"No valid bounding boxes (classes 0-3) in {annotation_path}. Skipping centering.\")\n",
    "        cv2.imwrite(output_image_path, image)\n",
    "        shutil.copy(annotation_path, output_annotation_path)\n",
    "        return\n",
    "\n",
    "    # Convert normalized coordinates to pixel values\n",
    "    box_center_x = int(((x_min + x_max) / 2) * original_w)\n",
    "    box_center_y = int(((y_min + y_max) / 2) * original_h)\n",
    "\n",
    "    # Calculate shift to center the bounding box center in the image\n",
    "    shift_x = (original_w // 2) - box_center_x\n",
    "    shift_y = (original_h // 2) - box_center_y\n",
    "\n",
    "    # Apply the shift to the image\n",
    "    transformation_matrix = np.float32([[1, 0, shift_x], [0, 1, shift_y]])\n",
    "    shifted_image = cv2.warpAffine(image, transformation_matrix, (original_w, original_h), borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))\n",
    "\n",
    "    # Save the shifted image\n",
    "    output_directory = os.path.dirname(output_image_path)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    cv2.imwrite(output_image_path, shifted_image)\n",
    "\n",
    "    # Update annotations\n",
    "    new_annotations = []\n",
    "    with open(annotation_path, \"r\") as annotation_file:\n",
    "        for annotation in annotation_file:\n",
    "            class_id, cx, cy, bw, bh = map(float, annotation.split())\n",
    "\n",
    "            # Adjust bounding box centers\n",
    "            cx = (cx * original_w + shift_x) / original_w\n",
    "            cy = (cy * original_h + shift_y) / original_h\n",
    "\n",
    "            # Clamp the bounding box coordinates to ensure they stay within bounds\n",
    "            x_min = max(0, cx - bw / 2)\n",
    "            y_min = max(0, cy - bh / 2)\n",
    "            x_max = min(1, cx + bw / 2)\n",
    "            y_max = min(1, cy + bh / 2)\n",
    "\n",
    "            # Recalculate bounding box center, width, and height\n",
    "            cx = (x_min + x_max) / 2\n",
    "            cy = (y_min + y_max) / 2\n",
    "            bw = x_max - x_min\n",
    "            bh = y_max - y_min\n",
    "\n",
    "            # Only append the bounding box if it still has valid dimensions\n",
    "            if bw > 0 and bh > 0:\n",
    "                new_annotations.append(f\"{int(class_id)} {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}\\n\")\n",
    "            else:\n",
    "                print(f\"Clamped box for class {class_id} has zero area and will not be included.\")\n",
    "\n",
    "    # Save updated annotations\n",
    "    with open(output_annotation_path, \"w\") as annotation_file:\n",
    "        annotation_file.writelines(new_annotations)\n",
    "\n",
    "    #print(f\"Centered image and annotations saved to: {output_image_path}, {output_annotation_path}\")\n",
    "\n",
    "\n",
    "def scale_image_and_update_annotations(src, ann_path, output_image_path, output_ann_path, scale_factor):\n",
    "    \"\"\"\n",
    "    Scales the image, centers the overlay within the original dimensions, and updates annotations.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = cv2.imread(src)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image not found: {src}\")\n",
    "\n",
    "    original_h, original_w = image.shape[:2]\n",
    "\n",
    "    # Scale the image\n",
    "    scaled_h, scaled_w = int(original_h * scale_factor), int(original_w * scale_factor)\n",
    "    scaled_image = cv2.resize(image, (scaled_w, scaled_h))\n",
    "\n",
    "    # Calculate offsets to center the scaled image\n",
    "    offset_y = max(0, (scaled_h - original_h) // 2)\n",
    "    offset_x = max(0, (scaled_w - original_w) // 2)\n",
    "\n",
    "    # Create a blank canvas for the original image size\n",
    "    new_image = np.zeros_like(image)  # Blank canvas for the scaled crop\n",
    "\n",
    "    # Extract the region from the scaled image that fits the original size\n",
    "    scaled_crop = scaled_image[\n",
    "        offset_y:offset_y + original_h,\n",
    "        offset_x:offset_x + original_w\n",
    "    ]\n",
    "    new_image[:scaled_crop.shape[0], :scaled_crop.shape[1]] = scaled_crop\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_directory = os.path.dirname(output_image_path)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Save the scaled image\n",
    "    cv2.imwrite(output_image_path, new_image)\n",
    "\n",
    "    # Update annotations\n",
    "    new_annotations = []\n",
    "    with open(ann_path, \"r\") as ann_file:\n",
    "        for annotation in ann_file:\n",
    "            class_id, cx, cy, bw, bh = map(float, annotation.split())\n",
    "\n",
    "            # Convert annotation to absolute values\n",
    "            cx_abs = cx * original_w\n",
    "            cy_abs = cy * original_h\n",
    "            bw_abs = bw * original_w\n",
    "            bh_abs = bh * original_h\n",
    "\n",
    "            # Scale and adjust the coordinates\n",
    "            cx_abs = (cx_abs * scale_factor) - offset_x\n",
    "            cy_abs = (cy_abs * scale_factor) - offset_y\n",
    "            bw_abs *= scale_factor\n",
    "            bh_abs *= scale_factor\n",
    "\n",
    "            # Calculate the bounding box coordinates\n",
    "            x_min = max(0, cx_abs - bw_abs / 2)\n",
    "            y_min = max(0, cy_abs - bh_abs / 2)\n",
    "            x_max = min(original_w, cx_abs + bw_abs / 2)\n",
    "            y_max = min(original_h, cy_abs + bh_abs / 2)\n",
    "\n",
    "            # Clamp bounding box dimensions to image boundaries\n",
    "            x_min = max(0, x_min)\n",
    "            y_min = max(0, y_min)\n",
    "            x_max = min(original_w, x_max)\n",
    "            y_max = min(original_h, y_max)\n",
    "\n",
    "            # Recalculate bounding box center, width, and height\n",
    "            cx_abs = (x_min + x_max) / 2\n",
    "            cy_abs = (y_min + y_max) / 2\n",
    "            bw_abs = x_max - x_min\n",
    "            bh_abs = y_max - y_min\n",
    "\n",
    "            # Skip bounding boxes with zero or negative dimensions\n",
    "            if bw_abs <= 0 or bh_abs <= 0:\n",
    "                print(f\"Clamped box for class {class_id} has zero area and will not be included.\")\n",
    "                continue\n",
    "\n",
    "            # Convert back to relative values\n",
    "            cx = cx_abs / original_w\n",
    "            cy = cy_abs / original_h\n",
    "            bw = bw_abs / original_w\n",
    "            bh = bh_abs / original_h\n",
    "\n",
    "            # Append updated annotation\n",
    "            new_annotations.append(f\"{int(class_id)} {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}\\n\")\n",
    "\n",
    "    # Save updated annotations\n",
    "    with open(output_ann_path, \"w\") as annotation_file:\n",
    "        annotation_file.writelines(new_annotations)\n",
    "\n",
    "    #print(f\"Scaled image saved to: {output_image_path}\")\n",
    "    #print(f\"Updated annotations saved to: {output_ann_path}\")\n",
    "\n",
    "def shift_image_and_update_annotations(\n",
    "        image_path, \n",
    "        annotation_path, \n",
    "        output_image_path, \n",
    "        output_annotation_path, \n",
    "        shift_x_pc=0.1, \n",
    "        shift_y_pc=0.1):\n",
    "    \"\"\"\n",
    "    Shifts the image horizontally/vertically and updates annotations accordingly.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        annotation_path (str): Path to the corresponding annotation file.\n",
    "        output_image_path (str): Path to save the shifted image.\n",
    "        output_annotation_path (str): Path to save the updated annotations.\n",
    "        shift_x_pc (float): Fraction of the image width to shift (-1 to 1).\n",
    "        shift_y_pc (float): Fraction of the image height to shift (-1 to 1).\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "    \n",
    "    original_h, original_w = image.shape[:2]\n",
    "\n",
    "    # Convert percentage shifts to pixel shifts\n",
    "    shift_x = int(original_w * shift_x_pc)\n",
    "    shift_y = int(original_h * shift_y_pc)\n",
    "\n",
    "    # Create a blank canvas for the shifted image\n",
    "    new_image = np.zeros_like(image)\n",
    "\n",
    "    # Handle vertical shift\n",
    "    if shift_y > 0:  # Shift down\n",
    "        new_image[shift_y:, :] = image[:-shift_y, :]\n",
    "    elif shift_y < 0:  # Shift up\n",
    "        new_image[:shift_y, :] = image[-shift_y:, :]\n",
    "    else:\n",
    "        new_image[:, :] = image[:, :]  # No vertical shift\n",
    "\n",
    "    # Handle horizontal shift\n",
    "    if shift_x > 0:  # Shift right\n",
    "        new_image[:, shift_x:] = new_image[:, :-shift_x]\n",
    "    elif shift_x < 0:  # Shift left\n",
    "        new_image[:, :shift_x] = new_image[:, -shift_x:]\n",
    "    else:\n",
    "        new_image[:, :] = new_image[:, :]  # No horizontal shift\n",
    "\n",
    "    # Save the shifted image\n",
    "    cv2.imwrite(output_image_path, new_image)\n",
    "\n",
    "    # Update annotations\n",
    "    new_annotations = []\n",
    "    with open(annotation_path, \"r\") as annotation_file:\n",
    "        for annotation in annotation_file:\n",
    "            class_id, cx, cy, bw, bh = map(float, annotation.split())\n",
    "\n",
    "            # Adjust bounding box centers\n",
    "            cx += shift_x_pc\n",
    "            cy += shift_y_pc\n",
    "\n",
    "            # Validate if the box stays in the valid range\n",
    "            if (cx - bw / 2 < 0 or cx + bw / 2 > 1 or\n",
    "                cy - bh / 2 < 0 or cy + bh / 2 > 1):\n",
    "                continue  # Skip bounding boxes that go out of bounds\n",
    "\n",
    "            # Append updated annotation\n",
    "            new_annotations.append(f\"{int(class_id)} {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}\\n\")\n",
    "\n",
    "    # Save updated annotations\n",
    "    with open(output_annotation_path, \"w\") as annotation_file:\n",
    "        annotation_file.writelines(new_annotations)\n",
    "\n",
    "    #print(f\"Shifted image saved to: {output_image_path}\")\n",
    "    #print(f\"Updated annotations saved to: {output_annotation_path}\")\n",
    "\n",
    "\n",
    "def process_folderOLD(src_fld, tgt_fld, job, scale_factor, shift_x_pc=0, shift_y_pc=0, scaling=False, shifting=False, center=False):\n",
    "    \"\"\"\n",
    "    Processes all images and annotations in a folder.\n",
    "    \"\"\"\n",
    "    print(f\"Beginning to process {job}...scale factor is: {scale_factor}\")\n",
    "    \n",
    "    #print(f\"tgt: {tgt_fld}, job: {job}\")\n",
    "    #print(f\"src: {src_fld}, job: {job}\")\n",
    "\n",
    "    src = os.path.join(src_fld, job)\n",
    "    tgt = os.path.join(tgt_fld, job)\n",
    "\n",
    "    #print(f\"tgt: {tgt}, job: {job}\")\n",
    "    #print(f\"src: {src}, job: {job}\")\n",
    "\n",
    "    # output_images_folder = tgt #os.path.join(output_folder, images_sub_folder)\n",
    "    #output_ann_folder = tgt #os.path.join(output_folder, annotations_sub_folder)\n",
    "    #os.makedirs(output_images_folder, exist_ok=True)\n",
    "    #os.makedirs(output_annotations_folder, exist_ok=True)\n",
    "    #output_images_folder = os.path.join(tgt, job)\n",
    "\n",
    "    #os.makedirs(output_folder, exist_ok=True)\n",
    "    image_files = [f for f in os.listdir(src_fld) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    os.makedirs(tgt, exist_ok=True)\n",
    "\n",
    "    for image_file in image_files:\n",
    "        #image_path = os.path.join(images_folder, image_file)\n",
    "        src_image_path = os.path.join(src, image_file)\n",
    "        #print(f\"src imgpath {src_image_path}\")\n",
    "        src_ann_path = os.path.join(src, os.path.splitext(image_file)[0] + \".txt\")\n",
    "        #annotation_path = os.path.join(annotations_folder, os.path.splitext(image_file)[0] + \".txt\")\n",
    "        if not os.path.exists(src_ann_path):\n",
    "            print(f\"Annotation missing for image: {image_file}, skipping.\")\n",
    "            continue\n",
    "        if center:\n",
    "            #output_image_path_center = os.path.join(tgt, f\"{image_file}_centered\")\n",
    "            # Append \"_centered\" to the image file name and retain the extension\n",
    "            output_image_path_center = os.path.join(tgt, f\"{os.path.splitext(image_file)[0]}_centered{os.path.splitext(image_file)[1]}\")\n",
    "             # Append \"_centered\" for the annotation file as well\n",
    "            output_ann_path_center = os.path.join(tgt, f\"{os.path.splitext(image_file)[0]}_centered.txt\")\n",
    "            # output_ann_path_center = os.path.join(tgt, f\"{os.path.splitext(image_file)[0]}_centered.txt\")\n",
    "            center_image_and_update_annotations(src_image_path, src_ann_path, output_image_path_center, output_ann_path_center)\n",
    "            #Pass items from this into the next operation  \n",
    "            src_image_path = output_image_path_center\n",
    "            src_ann_path = output_ann_path_center\n",
    "        \n",
    "        if shifting:\n",
    "            output_image_path_shift = os.path.join(tgt, f\"{image_file}_shifted\")\n",
    "            output_ann_path_shift = os.path.join(tgt, f\"{os.path.splitext(image_file)[0]}_shifted.txt\")\n",
    "            shift_image_and_update_annotations(src_image_path, src_ann_path, output_image_path_shift, output_ann_path_shift, shift_x_pc, shift_y_pc)\n",
    "            # make these the new input paths for further work \n",
    "            #src_image_path = output_image_path_shift\n",
    "            #src_ann_path = output_ann_path_shift\n",
    "            # Pass items from this into the scaling function \n",
    "            src_image_path = output_image_path_shift\n",
    "            src_ann_path = output_ann_path_shift\n",
    "        \n",
    "        if scaling:\n",
    "            scale_str = str(scale_factor).replace('.', '_')\n",
    "            #output_images_folder = f(\"{output_images_folder}_{scale_str}\")\n",
    "            output_image_path_scale = os.path.join(tgt, f\"{os.path.splitext(image_file)[0]}_scaled_{scale_str}\")\n",
    "            output_ann_path_scale =   os.path.join(tgt, f\"{os.path.splitext(image_file)[0]}_scaled_{scale_str}.txt\")\n",
    "            #output_image_path_scale = os.path.join(tgt, \"{image_file}_scaled_{scale_str}\")\n",
    "            #output_ann_path_scale = os.path.join(tgt, \"{os.path.splitext(image_file)[0]}_scaled_{scale_str}.txt\")\n",
    "            scale_image_and_update_annotations(src_image_path, src_ann_path, output_image_path_scale,  output_ann_path_scale, scale_factor)\n",
    "            #print(f\" source image path:  {src_image_path}\")\n",
    "            #print(f\" source annotation path: {src_ann_path}\")\n",
    "            #print(output_image_path_scale)\n",
    "            #print(output_ann_path_scale)\n",
    "            #print(1.5)\n",
    "    \n",
    "    print(f\"Augmentation cycle completed for {job}...\")\n",
    "    if shifting:\n",
    "        print(f\" - Vertical/horizontal shift applied (x: {shift_x_pc}, y: {shift_y_pc})\") #f\\n\n",
    "    if scaling:\n",
    "        print(f\" - Images scaled - scale factor: {scale_factor}\")\n",
    "    if center:\n",
    "        print(\"  - Images centered based on bounding boxes.\")\n",
    "\n",
    "\n",
    "def cleanup_centered_files(base_tgt):\n",
    "    \"\"\"\n",
    "    Deletes all files containing '_centered_' in their filenames\n",
    "    within the subfolders of base_tgt.\n",
    "\n",
    "    Args:\n",
    "        base_tgt (str): Path to the base directory.\n",
    "    \"\"\"\n",
    "    for root, _, files in os.walk(base_tgt):\n",
    "        for file in files:\n",
    "            if '_centered_' in file:\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"Deleted: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to delete {file_path}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def process_folder(src_fld, tgt_fld, job, scale_factor, shift_x_pc=0, shift_y_pc=0, scaling=False, shifting=False, center=False):\n",
    "    \"\"\"\n",
    "    Processes all images and annotations in a folder.\n",
    "    \"\"\"\n",
    "    print(f\"Beginning to process {job}...scale factor is: {scale_factor}\")\n",
    "    \n",
    "    src = os.path.normpath(os.path.join(src_fld, job))\n",
    "    tgt = os.path.normpath(os.path.join(tgt_fld, job))\n",
    "    os.makedirs(tgt, exist_ok=True)\n",
    "\n",
    "    image_files = [\n",
    "        f for f in os.listdir(src)\n",
    "        if f.lower().endswith(('.png', '.jpg', '.jpeg')) and \n",
    "        os.path.exists(os.path.join(src, os.path.splitext(f)[0] + \".txt\"))\n",
    "    ]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        src_image_path = os.path.join(src, image_file)\n",
    "        src_ann_path = os.path.join(src, os.path.splitext(image_file)[0] + \".txt\")\n",
    "\n",
    "        current_image_path = src_image_path\n",
    "        current_ann_path = src_ann_path\n",
    "\n",
    "        if center:\n",
    "            output_image_path_center = generate_output_path(tgt, image_file, \"centered\")\n",
    "            output_ann_path_center = generate_output_path(tgt, image_file, \"centered\", \".txt\")\n",
    "            center_image_and_update_annotations(current_image_path, current_ann_path, output_image_path_center, output_ann_path_center)\n",
    "            current_image_path, current_ann_path = output_image_path_center, output_ann_path_center\n",
    "\n",
    "        #if shifting:\n",
    "        #    output_image_path_shift = generate_output_path(tgt, image_file, \"shifted\")\n",
    "        #    output_ann_path_shift = generate_output_path(tgt, image_file, \"shifted\", \".txt\")\n",
    "        #    shift_image_and_update_annotations(current_image_path, current_ann_path, output_image_path_shift, output_ann_path_shift, shift_x_pc, shift_y_pc)\n",
    "        #    current_image_path, current_ann_path = output_image_path_shift, output_ann_path_shift\n",
    "\n",
    "        if scaling:\n",
    "            output_image_path_scale = generate_output_path(tgt, image_file, f\"scaled_{str(scale_factor).replace('.', '_')}\")\n",
    "            output_ann_path_scale = generate_output_path(tgt, image_file, f\"scaled_{str(scale_factor).replace('.', '_')}\", \".txt\")\n",
    "            scale_image_and_update_annotations(current_image_path, current_ann_path, output_image_path_scale, output_ann_path_scale, scale_factor)\n",
    "\n",
    "    # clean up the intermediate atage files with '_centered_' in the filename\n",
    "    cleanup_centered_files(tgt)\n",
    "\n",
    "    print(f\"Processing completed for job: {job}\")\n",
    " \n",
    "def preview_images(image_folder, annotation_folder, obj_names_path, preview_count=3):\n",
    "    \"\"\"\n",
    "    Displays images with bounding boxes and class labels.\n",
    "    Args:\n",
    "        image_folder (str): Folder containing images.\n",
    "        annotation_folder (str): Folder containing annotations.\n",
    "        obj_names_path (str): Path to the obj.names file.\n",
    "        preview_count (int): Number of images to preview.\n",
    "    \"\"\"\n",
    "    class_names = load_class_names(obj_names_path)\n",
    "    image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "    for image_file in image_files[:preview_count]:\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        annotation_path = os.path.join(annotation_folder, os.path.splitext(image_file)[0] + \".txt\")\n",
    "\n",
    "        if not os.path.exists(annotation_path):\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        preview = image.copy()\n",
    "\n",
    "        with open(annotation_path, \"r\") as f:\n",
    "            annotations = f.readlines()\n",
    "\n",
    "        for ann in annotations:\n",
    "            class_id, cx, cy, bw, bh = map(float, ann.split())\n",
    "            x_center = int(cx * image.shape[1])\n",
    "            y_center = int(cy * image.shape[0])\n",
    "            box_width = int(bw * image.shape[1])\n",
    "            box_height = int(bh * image.shape[0])\n",
    "            x1 = int(x_center - box_width / 2)\n",
    "            y1 = int(y_center - box_height / 2)\n",
    "            x2 = int(x_center + box_width / 2)\n",
    "            y2 = int(y_center + box_height / 2)\n",
    "            cv2.rectangle(preview, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            label = class_names[int(class_id)]\n",
    "            cv2.putText(preview, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 0, 0), 1)\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(cv2.cvtColor(preview, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Preview of {image_file}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Usage Section\n",
    "if __name__ == \"__main__\":\n",
    "    #base_folder = r'D:\\FlagDetectionDatasets\\ExportedDatasetsReduced\\AugTest'\n",
    "    #base_folder = r'D:\\FlagDetectionDatasets\\Augmentation\n",
    "\n",
    "    #output_folder = r'D:/FlagDetectionDatasets/ExportedDatasetsReduced/Augmentation/Job_30_scaled'\n",
    "    #annotations_sub_folder = \"obj_train_data\" \n",
    "    #images_sub_folder = \"obj_train_data\"  \n",
    "    #obj_names_path = os.path.join(base_folder, \"obj.names\")  # Path to obj.names\n",
    "\n",
    "    #base_folder = f'D:\\FlagDetectionDatasets\\Augmentation\\scaled\\source\\Job_88'\n",
    "\n",
    "    #base_folder = r'D:\\FlagDetectionDatasets\\Augmentation\\scaled\\source\\Job_88'\n",
    "    \n",
    "    #base_folder = r'D:\\FlagDetectionDatasets\\Augmentation\\scaled\\source\\test'\n",
    "    #base_folder = r'D:\\FlagDetectionDatasets\\Augmentation\\scaled\\source\\test\\1_shifted'\n",
    "    #output_folder = r'D:\\FlagDetectionDatasets\\Augmentation\\scaled\\augmented\\Job_88'\n",
    "    \n",
    "    # Parameters\n",
    "    #shift_percent = 0 #-.25  # Positive for right shift, negative for left shift\n",
    "\n",
    "    # Construct paths\n",
    "    #source_images_folder = os.path.join(base_folder, images_sub_folder)\n",
    "    #source_annotations_folder = os.path.join(base_folder, annotations_sub_folder)\n",
    "    #source_images_folder = base_folder\n",
    "    #source_annotations_folder = base_folder # annotations_sub_folder\n",
    "\n",
    "    # Parametersnorm\n",
    "    scale_factor = 1.7 #2.3 # 88 / job_36 / job_126 1.5 # 1.2\n",
    "    shift_x_pc = 0 #-.3  #20%\n",
    "    shift_y_pc = 0 #-.04 #0 #-.2 #.09 #.06 # minus pushes img up \n",
    "    preview_count = 3\n",
    "\n",
    "    # nEXT RUN \n",
    "    #process_folder(base_src,base_tgt,job='Job_7',scale_factor=1.8,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    # 23\n",
    "    # Job 22: scalefactor 1.9, shift_y_pc : .06    scaling = True,   shifting = True \n",
    "    \n",
    "    #base_src = r'D:/FlagDetectionDatasets/ExportedDatasetsReduced'\n",
    "\n",
    "    #base_tgt = r'D:/FlagDetectionDatasets/Augmentation/scaled/augmented'\n",
    "\n",
    "    #base_src = os.path.normpath('D:/FlagDetectionDatasets/ExportedDatasetsExtracted')\n",
    "    base_src = os.path.normpath('D:/FlagDetectionDatasets/ExportedDatasetsReduced')\n",
    "    base_tgt = os.path.normpath('D:/FlagDetectionDatasets/Augmentation/scaled/augmented')\n",
    "  \n",
    "    #process_folder(base_src,base_tgt,job='Job_88',scale_factor=2.2,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    # REDO process_folder(base_src,base_tgt,job='Job_23',scale_factor=1.8,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_7',scale_factor=2.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_11',scale_factor=2.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    # ry flag at home \n",
    "    #process_folder(base_src,base_tgt,job='Job_12',scale_factor=2.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_17',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_18',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "\n",
    "    # red flag home \n",
    "    #process_folder(base_src,base_tgt,job='Job_13',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_14',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_15',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_16',scale_factor=1.2,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "\n",
    "    # Ex quality blue + red \n",
    "    #process_folder(base_src,base_tgt,job='Job_21',scale_factor=1.5,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_22',scale_factor=1.5,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    \n",
    "    # REDO process_folder(base_src,base_tgt,job='Job_23',scale_factor=2.2,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    \n",
    "    #process_folder(base_src,base_tgt,job='Job_27',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_28',scale_factor=1.3,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_29',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "\n",
    "    #process_folder(base_src,base_tgt,job='Job_30',scale_factor=1.5,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_31',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_32',scale_factor=1.5,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_36',scale_factor=1.6,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_37',scale_factor=1.7,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_41',scale_factor=1.5,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    \n",
    "    process_folder(base_src,base_tgt,job='Job_42',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    process_folder(base_src,base_tgt,job='Job_48',scale_factor=1.5,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    process_folder(base_src,base_tgt,job='Job_50',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    \n",
    "    #process_folder(base_src,base_tgt,job='Job_51',scale_factor=1.8,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    \n",
    "    #process_folder(base_src,base_tgt,job='Job_54',scale_factor=2.5,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_55',scale_factor=2.5,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_55',scale_factor=3.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    # SKIP process_folder(base_src,base_tgt,job='Job_57',scale_factor=3.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_59',scale_factor=3.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "\n",
    "    #process_folder(base_src,base_tgt,job='Job_60',scale_factor=3.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_61',scale_factor=3.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    # sKIP process_folder(base_src,base_tgt,job='Job_65',scale_factor=3.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    # SKIP process_folder(base_src,base_tgt,job='Job_66',scale_factor=3.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    # skip rocess_folder(base_src,base_tgt,job='Job_67',scale_factor=3.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    # skip process_folder(base_src,base_tgt,job='Job_69',scale_factor=3.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_70',scale_factor=3.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    \n",
    "    process_folder(base_src,base_tgt,job='Job_72',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "\n",
    "    process_folder(base_src,base_tgt,job='Job_76',scale_factor=1.7,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    process_folder(base_src,base_tgt,job='Job_87',scale_factor=3.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_88',scale_factor=2.2,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_89',scale_factor=2.2,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    # kip process_folder(base_src,base_tgt,job='Job_95',scale_factor=2.2,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    # SKIP process_folder(base_src,base_tgt,job='Job_96',scale_factor=2.2,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    # skip process_folder(base_src,base_tgt,job='Job_98',scale_factor=2.2,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    process_folder(base_src,base_tgt,job='Job_104',scale_factor=3.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    process_folder(base_src,base_tgt,job='Job_105',scale_factor=2.6,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    process_folder(base_src,base_tgt,job='Job_106',scale_factor=2.7,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    # SKIP process_folder(base_src,base_tgt,job='Job_108',scale_factor=2.2,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    # process_folder(base_src,base_tgt,job='Job_109',scale_factor=2.2,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    process_folder(base_src,base_tgt,job='Job_114',scale_factor=2.5,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    process_folder(base_src,base_tgt,job='Job_115',scale_factor=2.2,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    process_folder(base_src,base_tgt,job='Job_116',scale_factor=2.2,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "\n",
    "    process_folder(base_src,base_tgt,job='Job_117',scale_factor=2.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    ## REDO ANNOTATIONS MESSED UP \n",
    "    # process_folder(base_src,base_tgt,job='Job_118',scale_factor=1.5,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    process_folder(base_src,base_tgt,job='Job_119',scale_factor=1.7,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    # GOOD process_folder(base_src,base_tgt,job='Job_121',scale_factor=3.0,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    #process_folder(base_src,base_tgt,job='Job_123',scale_factor=1.8,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    process_folder(base_src,base_tgt,job='Job_125',scale_factor=1.9,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    \n",
    "    process_folder(base_src,base_tgt,job='Job_126',scale_factor=1.5,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    \n",
    "    process_folder(base_src,base_tgt,job='Job_130',scale_factor=2.2,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    process_folder(base_src,base_tgt,job='Job_143',scale_factor=2.2,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    process_folder(base_src,base_tgt,job='Job_145',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    # sKIP process_folder(base_src,base_tgt,job='Job_146',scale_factor=2.2,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "\n",
    "    process_folder(base_src,base_tgt,job='Job_24_filter',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    process_folder(base_src,base_tgt,job='Job_25_filter',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "    process_folder(base_src,base_tgt,job='Job_27_filter',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "\n",
    "    process_folder(base_src,base_tgt,job='Job_ssim_24',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "\n",
    "    process_folder(base_src,base_tgt,job='Job_ssim_25',scale_factor=1.4,shift_x_pc=shift_x_pc,shift_y_pc=shift_y_pc,scaling = True, shifting = False,  center = True)\n",
    "\n",
    "\n",
    "    previewjob='Job_23'\n",
    "    #print(base_src)\n",
    "    preview_folder=  os.path.join(base_src, previewjob)\n",
    "    #obj_names_path=  os.path.join(base_src, \"obj.names\")\n",
    "    #preview_foldertmp = os.path.join(base_tmp, previewjob)\n",
    "    #preview_images(preview_foldertmp, preview_foldertmp, obj_names_path, preview_count=10)\n",
    "    #preview_images(preview_folder, preview_folder, obj_names_path, preview_count=10)\n",
    "\n",
    "    # Process folder with scaling and shifting (enable/disable as needed)\n",
    "    #print(\"Doing my thing on...\")\n",
    "  \n",
    "    # Job 22 > shift 12 y - scale \n",
    "    # Preview scaled images\n",
    "    #print(\"\\nPreviewing augmented images...\")\n",
    "    #preview_images(\n",
    "    #    source_images_fodef preview_images(image_folder, annotation_folder, obj_names_path, preview_count=3):#output_folder, #source_images_folder, \n",
    "    #    source_images_folder, #output_folder, # source_images_folder, \n",
    "    #    obj_names_path='D:\\FlagDetectionDatasets\\Augmentation\\scaled\\source\\obj.names',\n",
    "    #    preview_count=preview_count\n",
    "    #)\n",
    "    \n",
    "    # Beginning to process D:\\FlagDetectionDatasets\\Augmentation\\scaled\\source\\Job_11...scale factor is: 1.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7ed65-a807-44ef-ac00-f56948f08461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0ff8de-3490-4308-be3f-5af846eced60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
